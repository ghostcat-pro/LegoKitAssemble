{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Xm6FJ25mfz"
      },
      "source": [
        "# üß± Assignment 1 ‚Äî Assembling Lego Kits\n",
        "\n",
        "## Authors: Francisco Pinto, Jo√£o Soares, Jo√£o Viterbo\n",
        "\n",
        "**FEUP ‚Äî Computer Vision 2025/26**  \n",
        "This notebook performs all tasks required in the assignment, using OpenCV and Python in Google¬†Colab.\n",
        "\n",
        "All results are displayed inline and saved under `/results/`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load and Directory Creation"
      ],
      "metadata": {
        "id": "fKjCXHyC94cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SYSTEM SETUP AND DATA DOWNLOAD (Drive-mounted version) ---\n",
        "\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "# 1Ô∏è‚É£ Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2Ô∏è‚É£ Define source and destination\n",
        "# Replace the path below with the exact path where your \"Calibration\", \"Fault\", \"Isolated\", \"Kit\" folders live.\n",
        "# Tip: In Colab's left panel, navigate to \"drive/MyDrive\", right-click the folder ‚Üí \"Copy path\"\n",
        "src = '/content/drive/MyDrive/LEGO_DATA'   # üîÅ adjust this\n",
        "dst = '/content/data'\n",
        "\n",
        "# 3Ô∏è‚É£ Copy recursively (keeps subfolders)\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ All project data copied recursively to /content/data\")\n",
        "\n",
        "# 4Ô∏è‚É£ (Optional) Verify structure\n",
        "for root, dirs, files in os.walk(dst):\n",
        "    for f in files:\n",
        "        print(os.path.join(root, f))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "swGEysXs60Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS4saA7g5mf3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- SYSTEM SETUP AND DATA DOWNLOAD (copy link version - not working) ---\n",
        "'''\n",
        "import os, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt, glob\n",
        "from google.colab import drive\n",
        "import gdown\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Create folders\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Public Drive folder ID\n",
        "folder_url = 'https://drive.google.com/drive/folders/1OCikW87wfB8TGvcw4qtL0bdCelWt3-wV?usp=sharing'\n",
        "!gdown --folder $folder_url -O ./data --remaining-ok\n",
        "\n",
        "print('‚úÖ Data downloaded successfully.')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSFvJhFH5mf4"
      },
      "source": [
        "## 1Ô∏è‚É£ Camera Calibration\n",
        "\n",
        "We estimate intrinsic and extrinsic parameters for the camera using the provided chessboard images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# auxiliary code to find what is the best pattern size\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pick one sample image from the first folder\n",
        "test_img_path = glob.glob('./data/Calibration/calib1/*.png')[0]\n",
        "print(\"Testing image:\", test_img_path)\n",
        "\n",
        "img = cv2.imread(test_img_path)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "found_any = False\n",
        "for cols in range(5, 13):  # test 5‚Äì12 columns\n",
        "    for rows in range(4, 10):  # test 4‚Äì9 rows\n",
        "        ret, corners = cv2.findChessboardCorners(gray, (cols, rows), None)\n",
        "        if ret:\n",
        "            found_any = True\n",
        "            print(f\"‚úÖ Pattern found with size ({cols}, {rows})\")\n",
        "            vis = img.copy()\n",
        "            cv2.drawChessboardCorners(vis, (cols, rows), corners, ret)\n",
        "            plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Detected pattern size: ({cols}, {rows})\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            break\n",
        "    if found_any:\n",
        "        break\n",
        "\n",
        "if not found_any:\n",
        "    print(\"‚ùå No chessboard pattern detected in this image ‚Äî might not be a standard calibration grid.\")\n"
      ],
      "metadata": {
        "id": "fp27_nWaGbDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# auxiliary code to verify the pattern size\n",
        "\n",
        "import glob, cv2\n",
        "\n",
        "pattern_size = (11, 8)  # or (6, 7) depending on what you decided\n",
        "valid = 0\n",
        "images = glob.glob('./data/Calibration/calib2/*.png')\n",
        "for img_path in images:\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, _ = cv2.findChessboardCorners(gray, pattern_size, None)\n",
        "    if ret:\n",
        "        valid += 1\n",
        "print(f\"‚úÖ {valid}/{len(images)} images with detected corners in calib2\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ywaaT4IYFgDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intrinsic values calculation with a resume of results.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calibrate(folder):\n",
        "    # Chessboard configuration (12x9 squares ‚Üí 11x8 inner corners)\n",
        "    pattern_size = (11, 8)\n",
        "    square_size = 15.0  # millimeters\n",
        "\n",
        "    # Prepare 3D object points with physical scale\n",
        "    objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
        "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
        "    objp *= square_size\n",
        "\n",
        "    objpoints, imgpoints = [], []\n",
        "    images = glob.glob(f\"{folder}/*.png\")\n",
        "    img_size = None\n",
        "\n",
        "    for fname in images:\n",
        "        img = cv2.imread(fname)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
        "        if ret:\n",
        "            corners2 = cv2.cornerSubPix(\n",
        "                gray, corners, (11, 11), (-1, -1),\n",
        "                (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "            )\n",
        "            objpoints.append(objp)\n",
        "            imgpoints.append(corners2)\n",
        "            img_size = gray.shape[::-1]\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Chessboard not detected in {fname}\")\n",
        "\n",
        "    if len(objpoints) == 0 or img_size is None:\n",
        "        raise ValueError(f\"No valid calibration images found in {folder}\")\n",
        "\n",
        "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
        "\n",
        "    # Compute reprojection error\n",
        "    total_error = 0\n",
        "    for i in range(len(objpoints)):\n",
        "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
        "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
        "        total_error += error\n",
        "    mean_error = total_error / len(objpoints)\n",
        "\n",
        "    return mtx, dist, mean_error\n",
        "\n",
        "# === Run for all three folders ===\n",
        "for folder in ['calib1', 'calib2', 'calib3']:\n",
        "    fpath = f'./data/Calibration/{folder}'\n",
        "    try:\n",
        "        mtx, dist, err = calibrate(fpath)\n",
        "        print(f\"\\nüìÅ {folder}\")\n",
        "        print(\"Intrinsic matrix (K):\\n\", mtx)\n",
        "        print(\"Distortion coefficients:\\n\", dist.ravel())\n",
        "        print(f\"Mean reprojection error: {err:.4f}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ö†Ô∏è Skipping {folder}: {e}\")\n"
      ],
      "metadata": {
        "id": "e5s3TX-7Lr46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 1a)\n",
        "\n",
        "The calibration from calib2 was selected because it achieved the lowest mean reprojection error (0.0074 px), indicating the most accurate mapping between 3-D object points and image points.\n",
        "The intrinsics are also consistent with the other attempts, confirming that the solution is stable and physically plausible."
      ],
      "metadata": {
        "id": "FZ4fOvZjMh4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVsYglkY5mf5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Intrinsic values calculation with the print of the images.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calibrate(folder):\n",
        "    # correct pattern size found earlier\n",
        "    pattern_size = (11, 8)  # (columns, rows) of inner corners\n",
        "\n",
        "    # prepare object points\n",
        "    objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
        "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
        "\n",
        "    objpoints = []  # 3D points\n",
        "    imgpoints = []  # 2D points\n",
        "\n",
        "    images = glob.glob(f\"{folder}/*.png\")\n",
        "    img_size = None\n",
        "\n",
        "    for fname in images:\n",
        "        img = cv2.imread(fname)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
        "\n",
        "        if ret:\n",
        "            objpoints.append(objp)\n",
        "            corners2 = cv2.cornerSubPix(\n",
        "                gray, corners, (11, 11), (-1, -1),\n",
        "                (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "            )\n",
        "            imgpoints.append(corners2)\n",
        "            img_size = gray.shape[::-1]\n",
        "\n",
        "            img_vis = cv2.drawChessboardCorners(img.copy(), pattern_size, corners2, ret)\n",
        "            plt.imshow(cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB))\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Chessboard not detected in {fname}\")\n",
        "\n",
        "    if len(objpoints) == 0 or img_size is None:\n",
        "        raise ValueError(f\"No valid calibration images found in {folder}\")\n",
        "\n",
        "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "        objpoints, imgpoints, img_size, None, None\n",
        "    )\n",
        "\n",
        "    total_error = 0\n",
        "    for i in range(len(objpoints)):\n",
        "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
        "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
        "        total_error += error\n",
        "    mean_error = total_error / len(objpoints)\n",
        "\n",
        "    print(f\"Used {len(objpoints)} valid images for calibration in {folder}\")\n",
        "\n",
        "    return mtx, dist, mean_error\n",
        "\n",
        "for folder in ['calib1', 'calib2', 'calib3']:\n",
        "    fpath = f'./data/Calibration/{folder}'\n",
        "    try:\n",
        "        mtx, dist, err = calibrate(fpath)\n",
        "        print(f'‚úÖ {folder}: reprojection error = {err:.4f}')\n",
        "    except ValueError as e:\n",
        "        print(f'‚ö†Ô∏è Skipping {folder} ‚Üí {e}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbQoOvWv5mf5"
      },
      "source": [
        "### Extrinsic calibration (final setup)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code does more than requested. It is using all images to do the calibration and not only the\n",
        "# final_setup.png image\n",
        "# EXTRA WORK DONE\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === PARAMETERS ===\n",
        "pattern_size = (11, 8)    # inner corners per chessboard row/col\n",
        "square_size = 15.0        # mm per square\n",
        "folder = './data/Calibration/calib2'\n",
        "axis_len = 30             # length of drawn 3D axes (mm)\n",
        "\n",
        "# === LOAD CAMERA INTRINSICS ===\n",
        "# You must have defined or imported a calibrate(folder) function\n",
        "K, dist, _ = calibrate(folder)\n",
        "\n",
        "# === PREPARE CHESSBOARD POINTS (world coordinates) ===\n",
        "objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
        "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
        "objp *= square_size\n",
        "\n",
        "# === PROCESS ALL IMAGES ===\n",
        "images = glob.glob(f\"{folder}/*.png\")\n",
        "extrinsics = []\n",
        "reproj_errors = []\n",
        "\n",
        "for fname in images:\n",
        "    img = cv2.imread(fname)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
        "    if not ret:\n",
        "        print(f\"‚ö†Ô∏è Corners not detected in {fname}\")\n",
        "        continue\n",
        "\n",
        "    # Refine corner locations\n",
        "    corners2 = cv2.cornerSubPix(\n",
        "        gray, corners, (11, 11), (-1, -1),\n",
        "        (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "    )\n",
        "\n",
        "    # Compute extrinsics\n",
        "    success, rvec, tvec = cv2.solvePnP(objp, corners2, K, dist)\n",
        "    if not success:\n",
        "        print(f\"‚ö†Ô∏è PnP failed for {fname}\")\n",
        "        continue\n",
        "\n",
        "    # Compute reprojection error\n",
        "    projected, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
        "    error = cv2.norm(corners2, projected, cv2.NORM_L2) / len(projected)\n",
        "    reproj_errors.append(error)\n",
        "    extrinsics.append((fname, rvec, tvec, error))\n",
        "\n",
        "    # === VISUALIZE AXES ===\n",
        "    axis = np.float32([[axis_len, 0, 0],\n",
        "                       [0, axis_len, 0],\n",
        "                       [0, 0, -axis_len]]).reshape(-1, 3)\n",
        "    imgpts, _ = cv2.projectPoints(axis, rvec, tvec, K, dist)\n",
        "    corner = tuple(corners2[0].ravel().astype(int))\n",
        "    img = cv2.line(img, corner, tuple(imgpts[0].ravel().astype(int)), (255, 0, 0), 3)\n",
        "    img = cv2.line(img, corner, tuple(imgpts[1].ravel().astype(int)), (0, 255, 0), 3)\n",
        "    img = cv2.line(img, corner, tuple(imgpts[2].ravel().astype(int)), (0, 0, 255), 3)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"{fname.split('/')[-1]} | reproj err: {error:.3f}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Extrinsics computed for {len(extrinsics)}/{len(images)} images.\")\n",
        "\n",
        "# === SELECT BEST IMAGE (lowest reprojection error) ===\n",
        "if not extrinsics:\n",
        "    raise ValueError(\"No valid extrinsics computed. Check chessboard detections.\")\n",
        "\n",
        "best_fname, best_rvec, best_tvec, best_err = min(extrinsics, key=lambda x: x[3])\n",
        "print(f\"\\nüèÜ Best image: {best_fname.split('/')[-1]} (reproj error={best_err:.4f})\")\n",
        "\n",
        "# === COMPUTE FINAL EXTRINSIC MATRIX ===\n",
        "R, _ = cv2.Rodrigues(best_rvec)\n",
        "extrinsic_matrix = np.hstack([R, best_tvec])\n",
        "print(\"\\nRotation vector (rvec):\\n\", best_rvec)\n",
        "print(\"Translation vector t (mm):\\n\", best_tvec)\n",
        "print(\"Extrinsic matrix [R|t]:\\n\", extrinsic_matrix)\n",
        "\n",
        "# === PIXEL-TO-MM CONVERSION ===\n",
        "img_best = cv2.imread(best_fname)\n",
        "gray_best = cv2.cvtColor(img_best, cv2.COLOR_BGR2GRAY)\n",
        "ret, corners_best = cv2.findChessboardCorners(gray_best, pattern_size, None)\n",
        "corners_best = cv2.cornerSubPix(\n",
        "    gray_best, corners_best, (11, 11), (-1, -1),\n",
        "    (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        ")\n",
        "\n",
        "# Local pixel spacing\n",
        "cols, rows = pattern_size\n",
        "dists = []\n",
        "for r in range(rows):\n",
        "    for c in range(cols - 1):\n",
        "        i = r * cols + c\n",
        "        dists.append(np.linalg.norm(corners_best[i + 1] - corners_best[i]))\n",
        "for r in range(rows - 1):\n",
        "    for c in range(cols):\n",
        "        i = r * cols + c\n",
        "        j = (r + 1) * cols + c\n",
        "        dists.append(np.linalg.norm(corners_best[j] - corners_best[i]))\n",
        "\n",
        "px_per_square = float(np.mean(dists))\n",
        "mm_per_px = square_size / px_per_square\n",
        "print(f\"\\nüìè Pixel-to-mm conversion ‚âà {mm_per_px:.6f} mm/px (from avg square spacing)\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GbjnxpOa-0Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code does what is requested\n",
        "# uses final_setup.png to calculate the variables\n",
        "\n",
        "import cv2, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Load best intrinsics (from calib3)\n",
        "K, dist, _ = calibrate('./data/Calibration/calib2')\n",
        "\n",
        "# 2) Prepare object points in mm for 11x8 inner corners\n",
        "pattern_size = (11, 8)\n",
        "square_size = 15.0  # mm\n",
        "objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
        "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
        "objp *= square_size\n",
        "\n",
        "# 3) Load final setup image and detect corners\n",
        "img = cv2.imread('./data/Calibration/final_setup.png')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
        "if not ret:\n",
        "    raise ValueError(\"Chessboard not detected in final setup image.\")\n",
        "corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1),\n",
        "                            (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3))\n",
        "\n",
        "# 4) Solve for extrinsics\n",
        "ok, rvec, tvec = cv2.solvePnP(objp, corners2, K, dist)\n",
        "R, _ = cv2.Rodrigues(rvec)\n",
        "extrinsic_matrix = np.hstack([R, tvec])   # 3x4 [R|t]\n",
        "\n",
        "print(\"Rotation vector (rvec):\\n\", rvec)\n",
        "print(\"Translation vector t (mm):\\n\", tvec)\n",
        "print(\"Extrinsic matrix [R|t]:\\n\", extrinsic_matrix)\n",
        "\n",
        "# 5) Pixel-to-millimeter conversion (local estimate from chessboard spacing)\n",
        "# Use both horizontal and vertical neighbor distances for robustness\n",
        "dists = []\n",
        "cols, rows = pattern_size\n",
        "for r in range(rows):\n",
        "    for c in range(cols-1):  # horizontal neighbors\n",
        "        i = r*cols + c\n",
        "        dists.append(np.linalg.norm(corners2[i+1]-corners2[i]))\n",
        "for r in range(rows-1):\n",
        "    for c in range(cols):    # vertical neighbors\n",
        "        i = r*cols + c\n",
        "        j = (r+1)*cols + c\n",
        "        dists.append(np.linalg.norm(corners2[j]-corners2[i]))\n",
        "\n",
        "px_per_square = float(np.mean(dists))\n",
        "mm_per_px = square_size / px_per_square\n",
        "print(f\"Pixel-to-mm conversion ‚âà {mm_per_px:.6f} mm/px  (from avg square spacing)\")\n"
      ],
      "metadata": {
        "id": "LbmMchpoM1tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 1b)\n",
        "\n",
        "Extrinsic matrix\n",
        "\n",
        "[R|t]:\n",
        "\n",
        " [[-9.98391200e-01 -1.22530188e-02 -5.53613199e-02  6.41626142e+01]\n",
        "\n",
        " [ 8.67550580e-03 -9.97886105e-01  6.44054112e-02  3.56702439e+01]\n",
        "\n",
        " [-5.60334526e-02  6.38215083e-02  9.96387007e-01  2.66735075e+02]]\n",
        "\n",
        " Pixel-to-mm conversion ‚âà 0.330046 mm/px  (from avg square spacing)"
      ],
      "metadata": {
        "id": "OcxGI7v96_yB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTLWojyn5mf6"
      },
      "source": [
        "## 2Ô∏è‚É£ Isolated Bricks Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN RESULTS\n",
        "# USE TO CLEAN ALL RESULTS FOLDER\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "def clear_output_folder(folder_path):\n",
        "    \"\"\"Delete all files and subfolders inside the results directory.\"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "        for item in os.listdir(folder_path):\n",
        "            item_path = os.path.join(folder_path, item)\n",
        "            try:\n",
        "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
        "                    os.unlink(item_path)\n",
        "                elif os.path.isdir(item_path):\n",
        "                    shutil.rmtree(item_path)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error deleting {item_path}: {e}\")\n",
        "    else:\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "# --- Clear output folders before starting ---\n",
        "clear_output_folder(\"results\")\n",
        "print(\"üßπ Old results deleted. Ready to run fresh detection.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EISNWdv6ewOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMALL TEST TO DEFINE ROI MANUALLY\n",
        "\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "\n",
        "# Crop region (y1:y2, x1:x2)\n",
        "roi = img[0:400, 0:300]\n",
        "\n",
        "# Show ROI to confirm\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Selected ROI')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dmwyd5c6MuN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DETECT REGION OF INTEREST COMPRISING ALL THE BRICKS\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_brick_roi(img_bgr, show_steps=True):\n",
        "    \"\"\"Automatically detect the ROI that contains all colored bricks.\"\"\"\n",
        "\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define HSV color ranges for the main LEGO colors\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "        'white':  [(0, 0, 200), (180, 60, 255)]  # low saturation, high brightness\n",
        "    }\n",
        "\n",
        "    # Combine all color masks into one\n",
        "    combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lo), np.array(hi))\n",
        "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
        "\n",
        "    # Optional cleaning (remove small noise, fill gaps)\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, k)\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, k)\n",
        "\n",
        "    # Find all contours in the combined mask\n",
        "    cnts, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not cnts:\n",
        "        print(\"‚ö†Ô∏è No colored regions found ‚Äî check color ranges.\")\n",
        "        return None, None, combined_mask\n",
        "\n",
        "    # Compute bounding box that encloses all color contours\n",
        "    all_points = np.vstack(cnts)  # stack all contour points together\n",
        "    x, y, w, h = cv2.boundingRect(all_points)\n",
        "    roi = img_bgr[y:y+h, x:x+w]\n",
        "\n",
        "    if show_steps:\n",
        "        # Display mask and ROI overlay\n",
        "        vis = img_bgr.copy()\n",
        "        cv2.rectangle(vis, (x, y), (x+w, y+h), (0,255,0), 3)\n",
        "\n",
        "        plt.figure(figsize=(12,5))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Detected ROI on Original\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(combined_mask, cmap='gray')\n",
        "        plt.title(\"Combined Color Mask\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return roi, (x, y, w, h), combined_mask\n",
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "roi, bbox, mask = detect_brick_roi(img)\n",
        "\n",
        "if roi is not None:\n",
        "    print(f\"Detected ROI bounding box: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}\")\n",
        "    plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Cropped ROI (auto detected)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "K_8o_JGSS3fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DETECT ROI BY COLOR OF BRICKS\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_color_rois(img_bgr, show=True):\n",
        "    \"\"\"Detect one ROI per color (red, blue, green, yellow, white).\"\"\"\n",
        "\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "        #'white':  [(0, 0, 200), (180, 60, 255)]\n",
        "        'white':  [(0, 0, 200), (30, 50, 255)]  # my settings for white\n",
        "    }\n",
        "\n",
        "    color_bgr_map = {\n",
        "        'red': (0, 0, 255),\n",
        "        'blue': (255, 0, 0),\n",
        "        'green': (0, 255, 0),\n",
        "        'yellow': (0, 255, 255),\n",
        "        'white': (180, 180, 180)\n",
        "    }\n",
        "\n",
        "    color_rois = {}\n",
        "    vis = img_bgr.copy()\n",
        "\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        base = 'red' if 'red' in name else name\n",
        "        mask = cv2.inRange(hsv, np.array(lo), np.array(hi))\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not cnts:\n",
        "            continue\n",
        "        all_points = np.vstack(cnts)\n",
        "        x, y, w, h = cv2.boundingRect(all_points)\n",
        "        color_rois[base] = (x, y, w, h)\n",
        "        cv2.rectangle(vis, (x, y), (x+w, y+h), color_bgr_map[base], 2)\n",
        "        cv2.putText(vis, base, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base], 1)\n",
        "\n",
        "    if show:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Per-color ROIs\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return color_rois\n",
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "color_rois = detect_color_rois(img)\n",
        "print(color_rois)\n",
        "\n",
        "# Optional: crop and show one ROI\n",
        "for color, (x, y, w, h) in color_rois.items():\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"{color} ROI\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YQZrSrXlTrmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT FOCUSING ONLY ON THE WHITE BRICKS\n",
        "# EXPERIMENT WITH MASK\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Step 1: Load image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found at ./data/Isolated/colored_bricks.png\")\n",
        "\n",
        "# --- Step 2: Convert to HSV ---\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# --- Step 3: Define white color range ---\n",
        "# White = low saturation (S) and high brightness (V)\n",
        "lower_white = np.array([0, 0, 200])\n",
        "upper_white = np.array([180, 60, 255])\n",
        "\n",
        "# --- Step 4: Create binary mask ---\n",
        "mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "\n",
        "# --- Step 5: Morphological cleanup ---\n",
        "# This removes small dots and fills tiny holes\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, kernel)\n",
        "mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# --- Step 6: Optional blur to smooth edges ---\n",
        "mask_white = cv2.GaussianBlur(mask_white, (3, 3), 0)\n",
        "\n",
        "# --- Step 7: Display results ---\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask_white, cmap='gray')\n",
        "plt.title(\"White Mask\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 8: Print basic mask stats ---\n",
        "num_white_pixels = cv2.countNonZero(mask_white)\n",
        "mask_area_ratio = num_white_pixels / (mask_white.shape[0] * mask_white.shape[1])\n",
        "print(f\"Number of white pixels detected: {num_white_pixels}\")\n",
        "print(f\"White area ratio: {mask_area_ratio:.4f}\")\n",
        "\n",
        "# Optional: save mask for inspection\n",
        "cv2.imwrite('results/mask_white.png', mask_white)\n",
        "print(\"Saved mask to results/mask_white.png\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N0pWEXkaUx4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT FOCUSING ONLY ON THE WHITE BRICKS\n",
        "# TRY TO DETECT NUMBER OF BRICKS - UNSUCCEED !!!!\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Step 1: Load image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found at ./data/Isolated/colored_bricks.png\")\n",
        "\n",
        "# --- Step 2: Convert to HSV ---\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# --- Step 3: Define white color range ---\n",
        "# White = low saturation, high brightness\n",
        "lower_white = np.array([0, 0, 200])\n",
        "upper_white = np.array([180, 60, 255])\n",
        "\n",
        "# --- Step 4: Create binary mask ---\n",
        "mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "\n",
        "# --- Step 5: Morphological cleanup ---\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, kernel)\n",
        "mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# --- Step 6: Find contours (white regions) ---\n",
        "contours, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# --- Step 7: Draw bounding boxes for detected white bricks ---\n",
        "vis = img.copy()\n",
        "min_area = 500  # pixels; ignore tiny noise blobs\n",
        "white_bricks = 0\n",
        "\n",
        "for c in contours:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area < min_area:\n",
        "        continue\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    white_bricks += 1\n",
        "    cv2.rectangle(vis, (x, y), (x + w, y + h), (180, 180, 180), 2)\n",
        "    cv2.putText(vis, f'white #{white_bricks}', (x, y - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "\n",
        "# --- Step 8: Display results ---\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(mask_white, cmap='gray')\n",
        "plt.title('White Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Detected White Bricks ({white_bricks} found)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 9: Print stats ---\n",
        "num_white_pixels = cv2.countNonZero(mask_white)\n",
        "mask_area_ratio = num_white_pixels / (mask_white.shape[0] * mask_white.shape[1])\n",
        "print(f\"Detected white bricks: {white_bricks}\")\n",
        "print(f\"White pixels: {num_white_pixels} ({mask_area_ratio:.4%} of image)\")\n",
        "\n",
        "# --- Step 10: Save outputs ---\n",
        "os.makedirs('results', exist_ok=True)\n",
        "cv2.imwrite('results/mask_white.png', mask_white)\n",
        "cv2.imwrite('results/white_bricks_detected.png', vis)\n",
        "print(\"Saved mask and annotated image in 'results/' folder.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sZjhiOx7ViWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT FOCUSING ONLY ON THE WHITE BRICKS\n",
        "# TRY USING EDGES\n",
        "# TRY TO DETECT NUMBER OF BRICKS - UNSUCCEED !!!!\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Step 1: Load image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found\")\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# --- Step 2: Enhance edges with local contrast ---\n",
        "# Adaptive threshold detects slight brightness changes (edges/shadows)\n",
        "th = cv2.adaptiveThreshold(\n",
        "    gray, 255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,\n",
        "    51, 4  # block size, constant subtracted; tune C between 2‚Äì6\n",
        ")\n",
        "\n",
        "# --- Step 3: Clean the mask ---\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "mask = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)\n",
        "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# --- Step 4: Find contours of potential bricks ---\n",
        "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "vis = img.copy()\n",
        "\n",
        "min_area = 1000  # remove tiny noise\n",
        "white_bricks = 0\n",
        "\n",
        "for c in contours:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area < min_area:\n",
        "        continue\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    aspect = max(w, h) / (min(w, h) + 1e-6)\n",
        "    fill_ratio = area / (w*h + 1e-6)\n",
        "\n",
        "    # Filter by rectangularity and reasonable aspect\n",
        "    if 0.6 < fill_ratio < 1.1 and 0.5 < aspect < 3.0:\n",
        "        white_bricks += 1\n",
        "        cv2.rectangle(vis, (x, y), (x+w, y+h), (180, 180, 180), 2)\n",
        "        cv2.putText(vis, f'white #{white_bricks}', (x, y-5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "\n",
        "# --- Step 5: Display results ---\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.title('Adaptive Mask (edges of white bricks)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Detected White Bricks ({white_bricks} found)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 6: Save and report ---\n",
        "os.makedirs('results', exist_ok=True)\n",
        "cv2.imwrite('results/mask_white_adaptive.png', mask)\n",
        "cv2.imwrite('results/white_bricks_detected_adaptive.png', vis)\n",
        "\n",
        "print(f\"Detected white bricks: {white_bricks}\")\n",
        "print(\"Results saved in 'results/' folder.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bsmOIgjMWSzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPERIMENT FOCUSING ONLY ON THE WHITE BRICKS\n",
        "# FIRST APPLY MASK\n",
        "# SECOND TRY TO DETECT EDGES\n",
        "# TRY TO DETECT NUMBER OF BRICKS - UNSUCCEED !!!!\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Step 1: Load mask image ---\n",
        "mask = cv2.imread('results/mask_white.png', cv2.IMREAD_GRAYSCALE)\n",
        "if mask is None:\n",
        "    raise FileNotFoundError(\"mask_white.png not found in results/\")\n",
        "\n",
        "# --- Step 2: Edge detection ---\n",
        "# Canny detects transitions in the mask (useful if mask still includes background)\n",
        "edges = cv2.Canny(mask, 50, 150)\n",
        "\n",
        "# --- Step 3: Clean edges ---\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# --- Step 4: Find contours of connected white regions ---\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# --- Step 5: Analyze and visualize ---\n",
        "detected = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "min_area = 800  # ignore small fragments\n",
        "white_bricks = 0\n",
        "\n",
        "for c in contours:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area < min_area:\n",
        "        continue\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    aspect = max(w, h)/(min(w, h)+1e-6)\n",
        "    fill_ratio = area/(w*h+1e-6)\n",
        "    # simple shape filter for brick-like blobs\n",
        "    if 0.5 < aspect < 3.5 and fill_ratio > 0.55:\n",
        "        white_bricks += 1\n",
        "        cv2.rectangle(detected, (x, y), (x+w, y+h), (200,200,200), 2)\n",
        "        cv2.putText(detected, f'white #{white_bricks}', (x, y-5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
        "\n",
        "# --- Step 6: Show results ---\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(mask, cmap='gray'); plt.title('Input mask_white.png'); plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(edges, cmap='gray'); plt.title('Edges'); plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(cv2.cvtColor(detected, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Detected White Bricks ({white_bricks})')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 7: Save outputs ---\n",
        "os.makedirs('results', exist_ok=True)\n",
        "cv2.imwrite('results/mask_white_edges.png', edges)\n",
        "cv2.imwrite('results/white_bricks_from_mask.png', detected)\n",
        "print(f\"Detected {white_bricks} white bricks. Results saved in 'results/'.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i3EIjZ4jW9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FAILING TO DETECT WHITE PIECES\n",
        "\n",
        "Since the previous experiences where not going well a different approach was taken.\n",
        "\n",
        "There was no problem in detecting the colored ones, but for the whites it was not working.\n",
        "\n",
        "When the mask was applied I the human could identify the brick even with the \"noise\" caused by the background. And a dintinctive feature was prevalent, the stud.\n",
        "\n",
        "So the idea was, lets attack the image by pieces. Lets use the studs to create ROI (smaller ones) that allow then to apply the detection of the pieces.\n",
        "\n",
        "The studs could be detected almost 100%. It was not perfect but were enough to apply a cluterization to create smaller regions (ROI).\n",
        "\n",
        "It was oberved that some cluster have an overlap, so a treatment was applied to eliminate overlaps.\n",
        "\n",
        "Then the MASK was applied by ROI by color and it worked 100%.\n"
      ],
      "metadata": {
        "id": "T4lIixPG8k7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DETECT THE PIECES BY THE STUDS\n",
        "# THIS WAS DONE SINCE USING ONLY MASK COLOR OVER ALL THE IMAGE WAS NOT WORKING\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Step 1: Load and prepare image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found\")\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray = cv2.medianBlur(gray, 5)\n",
        "\n",
        "# --- Step 2: Detect circles using HoughCircles ---\n",
        "# Adjust these parameters depending on stud size and contrast\n",
        "circles = cv2.HoughCircles(\n",
        "    gray,\n",
        "    cv2.HOUGH_GRADIENT,\n",
        "    dp=1.2,             # inverse accumulator ratio (1.0‚Äì2.0 typical)\n",
        "    minDist=25,         # minimum distance between circle centers (adjust!)\n",
        "    param1=100,         # Canny high threshold\n",
        "    param2=15,          # smaller = more sensitive, but more false positives - initial 20\n",
        "    minRadius=6,        # min stud radius in pixels\n",
        "    maxRadius=15        # max stud radius\n",
        ")\n",
        "\n",
        "# --- Step 3: Draw detected circles ---\n",
        "vis = img.copy()\n",
        "stud_centers = []\n",
        "\n",
        "if circles is not None:\n",
        "    circles = np.uint16(np.around(circles))\n",
        "    for (x, y, r) in circles[0, :]:\n",
        "        cv2.circle(vis, (x, y), r, (0, 255, 0), 2)\n",
        "        cv2.circle(vis, (x, y), 2, (0, 0, 255), 3)\n",
        "        stud_centers.append((x, y, r))\n",
        "\n",
        "print(f\"Detected {len(stud_centers)} studs (circular bumps).\")\n",
        "\n",
        "# --- Step 4: Display results ---\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Detected LEGO Studs ({len(stud_centers)})\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# --- Step 5: Save results ---\n",
        "os.makedirs('results', exist_ok=True)\n",
        "cv2.imwrite('results/lego_studs_detected.png', vis)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s6-6DyzhX_Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLUSTER STUDS TO FIND ROI\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# --- Step 1: Load image and detect studs (reuse from before) ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray = cv2.medianBlur(gray, 5)\n",
        "\n",
        "circles = cv2.HoughCircles(\n",
        "    gray,\n",
        "    cv2.HOUGH_GRADIENT,\n",
        "    dp=1.2,\n",
        "    minDist=25,\n",
        "    param1=100,\n",
        "    param2=15,        # inital 20\n",
        "    minRadius=6,\n",
        "    maxRadius=15\n",
        ")\n",
        "\n",
        "if circles is None:\n",
        "    raise RuntimeError(\"No studs detected!\")\n",
        "\n",
        "circles = np.uint16(np.around(circles[0, :]))\n",
        "stud_points = np.array([[x, y] for x, y, r in circles])\n",
        "\n",
        "# --- Step 2: Cluster nearby studs using DBSCAN ---\n",
        "# eps = max distance between studs in a cluster; min_samples = minimum studs per cluster\n",
        "clustering = DBSCAN(eps=60, min_samples=2).fit(stud_points)\n",
        "labels = clustering.labels_\n",
        "\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "print(f\"Detected {len(stud_points)} studs and {n_clusters} clusters (potential bricks).\")\n",
        "\n",
        "# --- Step 3: Draw clusters and compute ROIs ---\n",
        "vis = img.copy()\n",
        "roi_list = []\n",
        "for cluster_id in range(n_clusters):\n",
        "    cluster_points = stud_points[labels == cluster_id]\n",
        "    if len(cluster_points) < 4:\n",
        "        continue  # we only want 4-stud bricks\n",
        "\n",
        "    x_min, y_min = np.min(cluster_points, axis=0)\n",
        "    x_max, y_max = np.max(cluster_points, axis=0)\n",
        "\n",
        "    # Slight margin around the studs\n",
        "    margin = 10\n",
        "    x1, y1, x2, y2 = x_min - margin, y_min - margin, x_max + margin, y_max + margin\n",
        "    roi_list.append((int(x1), int(y1), int(x2 - x1), int(y2 - y1)))\n",
        "\n",
        "    # Draw ROI rectangle\n",
        "    cv2.rectangle(vis, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
        "    cv2.putText(vis, f'ROI #{len(roi_list)}', (int(x1), int(y1) - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
        "\n",
        "# --- Step 4: Display results ---\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Grouped 4-Stud ROIs ({len(roi_list)} bricks)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 5: Optionally crop and save each ROI ---\n",
        "os.makedirs('results', exist_ok=True)\n",
        "for i, (x, y, w, h) in enumerate(roi_list, start=1):\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    cv2.imwrite(f'results/brick_roi_{i}.png', roi)\n",
        "\n",
        "print(f\"Saved {len(roi_list)} ROIs in 'results/' folder.\")\n"
      ],
      "metadata": {
        "id": "yB4KDHoEYhJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 1a)\n",
        "\n",
        "Previous code show the creation of ROI, in this case 9 regions of interest were created.\n",
        "\n",
        "Next cell will treat them to find overlap and eliminate if there exist."
      ],
      "metadata": {
        "id": "P9YgnmNtA0bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE ROI WITH OVERLAP\n",
        "# DONE THIS TO HAVE REGIONS THAT CAN BE USED AS ROI TO FIND THE BRICKS\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def remove_overlapping_rois(roi_list, iou_threshold=0.3, dist_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Improved version: removes overlapping or nearby ROIs, keeping only the largest.\n",
        "    - iou_threshold: standard intersection-over-union threshold\n",
        "    - dist_threshold: normalized center distance threshold (fraction of min dimension)\n",
        "    \"\"\"\n",
        "    def overlap_score(a, b):\n",
        "        # compute intersection area\n",
        "        xA = max(a[0], b[0])\n",
        "        yA = max(a[1], b[1])\n",
        "        xB = min(a[0]+a[2], b[0]+b[2])\n",
        "        yB = min(a[1]+a[3], b[1]+b[3])\n",
        "        interW = max(0, xB - xA)\n",
        "        interH = max(0, yB - yA)\n",
        "        interArea = interW * interH\n",
        "        if interArea == 0:\n",
        "            return 0.0\n",
        "        areaA, areaB = a[2]*a[3], b[2]*b[3]\n",
        "        # relative overlap (more aggressive)\n",
        "        return interArea / min(areaA, areaB)\n",
        "\n",
        "    def center_distance(a, b):\n",
        "        ax, ay = a[0] + a[2]/2, a[1] + a[3]/2\n",
        "        bx, by = b[0] + b[2]/2, b[1] + b[3]/2\n",
        "        return np.hypot(ax - bx, ay - by)\n",
        "\n",
        "    sorted_rois = sorted(roi_list, key=lambda r: r[2]*r[3], reverse=True)\n",
        "    final_rois = []\n",
        "\n",
        "    for box in sorted_rois:\n",
        "        keep = True\n",
        "        for kept in final_rois:\n",
        "            overlap = overlap_score(box, kept)\n",
        "            dist = center_distance(box, kept)\n",
        "            # compute normalized distance\n",
        "            min_dim = min(box[2], box[3], kept[2], kept[3])\n",
        "            if overlap > 0.25 or dist < min_dim * dist_threshold:\n",
        "                keep = False\n",
        "                break\n",
        "        if keep:\n",
        "            final_rois.append(box)\n",
        "\n",
        "    return final_rois\n",
        "\n",
        "\n",
        "\n",
        "# --- Example usage after your DBSCAN grouping code ---\n",
        "filtered_rois = remove_overlapping_rois(roi_list, iou_threshold=0.3)\n",
        "print(f\"Filtered from {len(roi_list)} ‚Üí {len(filtered_rois)} ROIs (removed overlaps)\")\n",
        "\n",
        "# --- Visualize filtered ROIs ---\n",
        "vis_filtered = img.copy()\n",
        "for i, (x, y, w, h) in enumerate(filtered_rois, start=1):\n",
        "    cv2.rectangle(vis_filtered, (x, y), (x+w, y+h), (0,255,255), 2)\n",
        "    cv2.putText(vis_filtered, f\"ROI#{i}\", (x, y-5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 1)\n",
        "\n",
        "cv2.imwrite(\"results/lego_rois_filtered.png\", vis_filtered)\n",
        "\n",
        "print(\"\\n‚úÖ Final non-overlapping ROIs:\")\n",
        "for i, (x, y, w, h) in enumerate(filtered_rois, start=1):\n",
        "    print(f\"ROI #{i}: x={x}, y={y}, w={w}, h={h}, area={w*h}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L7iqzXS6bB1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND WHITE BRICKS IN EACH ROI\n",
        "# ONLY the white are being identified.\n",
        "# PROOF OF CONCEPT\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.makedirs(\"results/roi_masks\", exist_ok=True)\n",
        "\n",
        "# --- Load original image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found: ./data/Isolated/colored_bricks.png\")\n",
        "\n",
        "# üß© Example placeholder ROIs (use your real ones if available)\n",
        "# filtered_rois = [(x, y, w, h), ...]\n",
        "# If you already have filtered_rois defined, this block will be skipped\n",
        "if \"filtered_rois\" not in locals():\n",
        "    print(\"‚ö†Ô∏è No filtered_rois found ‚Äî using demo ROIs\")\n",
        "    h, w = img.shape[:2]\n",
        "    filtered_rois = [(50, 50, w-100, h-100)]  # one ROI covering most of the image\n",
        "\n",
        "# üñºÔ∏è Create the global visualization canvas\n",
        "vis_global = img.copy()\n",
        "\n",
        "# --- Iterate through each ROI ---\n",
        "for i, (x, y, w, h) in enumerate(filtered_rois, start=1):\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define white range (fine-tuned for local detection)\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 60, 255])\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "\n",
        "    # Morphological cleaning\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Find contours of white regions\n",
        "    contours, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    min_area = 2000  # adjust this value based on image scale\n",
        "    white_count = 0\n",
        "    vis = roi.copy()\n",
        "\n",
        "    for c in contours:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area < min_area:\n",
        "            continue  # skip tiny false detections\n",
        "\n",
        "        x2, y2, w2, h2 = cv2.boundingRect(c)\n",
        "        gx1, gy1 = x + x2, y + y2\n",
        "        gx2, gy2 = gx1 + w2, gy1 + h2\n",
        "\n",
        "        # Draw both on the ROI and on the global visualization\n",
        "        cv2.rectangle(vis, (x2, y2), (x2 + w2, y2 + h2), (180, 180, 180), 2)\n",
        "        cv2.rectangle(vis_global, (gx1, gy1), (gx2, gy2), (180, 180, 180), 2)\n",
        "        cv2.putText(vis_global, 'white', (gx1, gy1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "        white_count += 1\n",
        "\n",
        "    # --- Display / save ---\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(mask_white, cmap='gray')\n",
        "    plt.title(f\"ROI {i} mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"ROI {i} white bricks: {white_count}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    cv2.imwrite(f\"results/roi_masks/roi_{i}_mask.png\", mask_white)\n",
        "    cv2.imwrite(f\"results/roi_masks/roi_{i}_detected.png\", vis)\n",
        "    print(f\"ROI #{i}: Detected {white_count} white bricks. Saved results.\")\n",
        "\n",
        "# üñºÔ∏è Finally save the global visualization\n",
        "cv2.imwrite(\"results/roi_masks/global_white_detections.png\", vis_global)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cv2.cvtColor(vis_global, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Global White Brick Detections\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N_tTwAEcgpZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISPLAY IN ORIGINAL PICTURE WHERE THE WHITE BRICKS ARE\n",
        "# FIND THE WHITE BRICKS\n",
        "# Only the White are being identified\n",
        "# PROOF OF CONCEPT\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.makedirs(\"results/final\", exist_ok=True)\n",
        "\n",
        "# --- Step 1: Load original image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found\")\n",
        "\n",
        "# Example: your list of filtered, non-overlapping ROIs\n",
        "# filtered_rois = [(x, y, w, h), ...]\n",
        "\n",
        "# --- Step 2: Initialize a copy for visualization ---\n",
        "vis_global = img.copy()\n",
        "global_white_count = 0\n",
        "\n",
        "# --- Step 3: Process each ROI ---\n",
        "for i, (x, y, w, h) in enumerate(filtered_rois, start=1):\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define \"white\" range\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 60, 255])\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "\n",
        "    # Morphological clean-up\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Find contours (white blobs)\n",
        "    contours, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for c in contours:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area < 2000:  # small noise filter\n",
        "            continue\n",
        "        x2, y2, w2, h2 = cv2.boundingRect(c)\n",
        "\n",
        "        # Convert local ROI coordinates ‚Üí global coordinates\n",
        "        gx1, gy1 = x + x2, y + y2\n",
        "        gx2, gy2 = gx1 + w2, gy1 + h2\n",
        "\n",
        "        # Draw rectangle on global image\n",
        "        cv2.rectangle(vis_global, (gx1, gy1), (gx2, gy2), (180, 180, 180), 2)\n",
        "        cv2.putText(vis_global, f'white', (gx1, gy1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "        global_white_count += 1\n",
        "\n",
        "# --- Step 4: Display global results ---\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(cv2.cvtColor(vis_global, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Detected White Bricks (total = {global_white_count})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --- Step 5: Save the final annotated image ---\n",
        "cv2.imwrite(\"results/final/white_bricks_on_original.png\", vis_global)\n",
        "print(f\"‚úÖ Done. Found {global_white_count} white bricks. Saved annotated image to results/final/white_bricks_on_original.png\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GYm18lH6c4UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISPLAY IN ORIGINAL PICTURE WHERE BRICKS ARE\n",
        "# FIND ALL BRICKS\n",
        "# DISPLAY IN ORIGINAL PICTURE\n",
        "# FINAL RESULT\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.makedirs(\"results/final\", exist_ok=True)\n",
        "\n",
        "# --- Load the original image ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found\")\n",
        "\n",
        "# --- Assume you already have your final filtered ROIs ---\n",
        "# filtered_rois = [(x, y, w, h), ...]\n",
        "\n",
        "# --- Define color ranges in HSV ---\n",
        "color_ranges = {\n",
        "    'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "    'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "    'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "    'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "    'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "    'white':  [(0, 0, 200), (180, 60, 255)]\n",
        "}\n",
        "\n",
        "# --- Assign BGR colors for drawing ---\n",
        "color_bgr_map = {\n",
        "    'red': (0, 0, 255),\n",
        "    'blue': (255, 0, 0),\n",
        "    'green': (0, 255, 0),\n",
        "    'yellow': (0, 255, 255),\n",
        "    'white': (200, 200, 200)\n",
        "}\n",
        "\n",
        "# --- Prepare visualization image ---\n",
        "vis_global = img.copy()\n",
        "results = []\n",
        "\n",
        "# --- Process each ROI ---\n",
        "for i, (x, y, w, h) in enumerate(filtered_rois, start=1):\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    color_counts = {c: 0 for c in ['red', 'blue', 'green', 'yellow', 'white']}\n",
        "\n",
        "    for color, (lower, upper) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "\n",
        "        # Merge red1 + red2\n",
        "        base_color = 'red' if 'red' in color else color\n",
        "\n",
        "        # Morphological cleanup\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        min_area = 800  # Adjust for your scale\n",
        "        for c in contours:\n",
        "            area = cv2.contourArea(c)\n",
        "            if area < min_area:\n",
        "                continue\n",
        "            color_counts[base_color] += 1\n",
        "            x2, y2, w2, h2 = cv2.boundingRect(c)\n",
        "            gx1, gy1 = x + x2, y + y2\n",
        "            gx2, gy2 = gx1 + w2, gy1 + h2\n",
        "            cv2.rectangle(vis_global, (gx1, gy1), (gx2, gy2), color_bgr_map[base_color], 2)\n",
        "            cv2.putText(vis_global, base_color, (gx1, gy1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base_color], 1)\n",
        "\n",
        "    for c, count in color_counts.items():\n",
        "        if count > 0:\n",
        "            results.append({'ROI': i, 'Color': c, 'Count': count})\n",
        "\n",
        "# --- Convert results to DataFrame ---\n",
        "df_colors = pd.DataFrame(results)\n",
        "summary = df_colors.groupby('Color')['Count'].sum().reset_index()\n",
        "\n",
        "# --- Display summary ---\n",
        "print(\"üé® Summary of bricks by color:\")\n",
        "print(summary)\n",
        "\n",
        "# --- Save summary ---\n",
        "summary.to_csv('results/final/brick_color_summary.csv', index=False)\n",
        "\n",
        "# --- Show final annotated image ---\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(vis_global, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Detected Bricks by Color\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "cv2.imwrite(\"results/final/bricks_by_color.png\", vis_global)\n",
        "print(\"‚úÖ Annotated image saved to results/final/bricks_by_color.png\")\n"
      ],
      "metadata": {
        "id": "a-2RXXbq6Ll5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 2b)\n",
        "\n",
        "Previous code show all the bricks being counted and identified in the image colored_bricks.png\n",
        "\n",
        "Result stored in bricks_by_color.png"
      ],
      "metadata": {
        "id": "iZouxHpH-6x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EXTRA EXPERIMENTS\n",
        "\n",
        "Tried solution to find all bricks.\n",
        "Problems with white."
      ],
      "metadata": {
        "id": "M1gVWVeRBFxv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aME5wUVN5mf6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# APPLY a MASK for each color to ease detection\n",
        "# TRYING TO DETECT ALL BRICKS\n",
        "# PLAYING WITH THE SETTINGS OF THE WHITE COLOR\n",
        "# USING PWHIT TO EXPERIMENT.\n",
        "# UNSUCCESSFULL\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def count_colors(img):\n",
        "    # Convert from BGR (OpenCV default) to HSV\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define color ranges in HSV (adjusted for your image)\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "        'white':  [(0, 0, 200), (180, 30, 255)],\n",
        "        'pwhite': [(0, 0, 200), (30, 50, 255)]\n",
        "    }\n",
        "\n",
        "    counts = {}\n",
        "\n",
        "    for color, (lower, upper) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "        count = cv2.countNonZero(mask)\n",
        "        base_color = 'red' if 'red' in color else color\n",
        "        counts[base_color] = counts.get(base_color, 0) + count\n",
        "        plt.figure(); plt.imshow(mask,cmap='gray'); plt.title(color)\n",
        "\n",
        "    return counts\n",
        "\n",
        "\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "counts = count_colors(img)\n",
        "df = pd.DataFrame(list(counts.items()), columns=['Color','Count'])\n",
        "\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY a MASK for each color to ease detection\n",
        "# TRYING TO DETECT ALL BRICKS\n",
        "# PLAYING WITH THE SETTINGS OF THE WHITE COLOR\n",
        "# USING PWHIT TO EXPERIMENT.\n",
        "# UNSUCCESSFULL\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mask_white(img_bgr):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    lower_hsv_white = np.array([0, 0, 200], dtype=np.uint8)\n",
        "    upper_hsv_white = np.array([180, 60, 255], dtype=np.uint8)\n",
        "    hsv_white = cv2.inRange(hsv, lower_hsv_white, upper_hsv_white)\n",
        "\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L, A, B = cv2.split(lab)\n",
        "    L_min, a_tol, b_tol = 200, 15, 15\n",
        "    lab_white = (\n",
        "        (L >= L_min) &\n",
        "        (cv2.absdiff(A, 128) <= a_tol) &\n",
        "        (cv2.absdiff(B, 128) <= b_tol)\n",
        "    ).astype(np.uint8) * 255\n",
        "\n",
        "    white_mask = cv2.bitwise_or(hsv_white, lab_white)\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, k)\n",
        "    white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, k)\n",
        "    return white_mask\n",
        "\n",
        "\n",
        "def count_and_display_bricks(img_bgr, min_area_ratio=0.0002):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    counts = {'red':0,'blue':0,'green':0,'yellow':0,'white':0,'pwhite':0}\n",
        "\n",
        "    # Colors in HSV space\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "        'pwhite': [(0, 0, 200), (30, 50, 255)]\n",
        "    }\n",
        "\n",
        "    # Output copy for visualization\n",
        "    vis = img_bgr.copy()\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    min_area = int(min_area_ratio * h * w)\n",
        "\n",
        "    color_bgr_map = {\n",
        "        'red': (0,0,255),\n",
        "        'blue': (255,0,0),\n",
        "        'green': (0,255,0),\n",
        "        'yellow': (0,255,255),\n",
        "        'white': (200,200,200),\n",
        "        'pwhite': (200,200,200)\n",
        "    }\n",
        "\n",
        "    # Process all non-white colors\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lo, np.uint8), np.array(hi, np.uint8))\n",
        "        base = 'red' if 'red' in name else name\n",
        "        mask = cv2.medianBlur(mask, 5)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        bricks = [c for c in cnts if cv2.contourArea(c) > min_area]\n",
        "        counts[base] += len(bricks)\n",
        "        # Draw each detected brick\n",
        "        for c in bricks:\n",
        "            x,y,wc,hc = cv2.boundingRect(c)\n",
        "            cv2.rectangle(vis, (x,y), (x+wc, y+hc), color_bgr_map[base], 2)\n",
        "            cv2.putText(vis, base, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base], 1)\n",
        "\n",
        "    # Handle white separately\n",
        "    white_mask = mask_white(img_bgr)\n",
        "    cnts, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    white_bricks = []\n",
        "    for c in cnts:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area <= min_area:\n",
        "            continue\n",
        "        x,y,wc,hc = cv2.boundingRect(c)\n",
        "        rect_area = wc*hc\n",
        "        fill_ratio = area/(rect_area+1e-6)\n",
        "        aspect = max(wc,hc)/(min(wc,hc)+1e-6)\n",
        "        if fill_ratio>0.65 and aspect<6.0:\n",
        "            white_bricks.append(c)\n",
        "            cv2.rectangle(vis, (x,y), (x+wc, y+hc), color_bgr_map['white'], 2)\n",
        "            cv2.putText(vis, 'white', (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50,50,50), 1)\n",
        "\n",
        "    counts['white'] = len(white_bricks)\n",
        "\n",
        "    # Display annotated image\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.title(\"Detected bricks by color\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame(sorted(counts.items()), columns=['Color','Num_Bricks'])\n",
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "df = count_and_display_bricks(img)\n",
        "print(df)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qUWyPtmnE_Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY a MASK for each color to ease detection\n",
        "# TRYING TO DETECT ALL BRICKS\n",
        "# SPECIAL TREATMENT FOR WHITE\n",
        "# UNSUCCESSFULL\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_white_bricks_on_white_bg(img_bgr, colored_mask=None, min_area_ratio=0.0002):\n",
        "    \"\"\"Detects white bricks using edges + shape analysis, optionally excluding colored regions.\"\"\"\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = gray.shape\n",
        "    min_area = int(min_area_ratio * h * w)\n",
        "\n",
        "    # Remove colored areas from search (so we don‚Äôt mix)\n",
        "    if colored_mask is not None:\n",
        "        mask_inv = cv2.bitwise_not(colored_mask)\n",
        "    else:\n",
        "        mask_inv = np.ones_like(gray) * 255\n",
        "\n",
        "    # Slight blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "\n",
        "    # Detect edges\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # Mask to ignore colored zones\n",
        "    edges = cv2.bitwise_and(edges, edges, mask=mask_inv)\n",
        "\n",
        "    # Close small gaps in edges\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, k, iterations=1)\n",
        "\n",
        "    # Find contours\n",
        "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    white_bricks = []\n",
        "    for c in cnts:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area <= min_area:\n",
        "            continue\n",
        "        x,y,wc,hc = cv2.boundingRect(c)\n",
        "        rect_area = wc*hc\n",
        "        fill_ratio = area/(rect_area+1e-6)\n",
        "        aspect = max(wc,hc)/(min(wc,hc)+1e-6)\n",
        "        if fill_ratio>0.65 and aspect<6.0:\n",
        "            white_bricks.append(c)\n",
        "    return white_bricks\n",
        "\n",
        "\n",
        "def count_and_display_bricks(img_bgr):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    min_area = int(0.0002 * h * w)\n",
        "\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "    }\n",
        "\n",
        "    color_bgr_map = {\n",
        "        'red': (0,0,255),\n",
        "        'blue': (255,0,0),\n",
        "        'green': (0,255,0),\n",
        "        'yellow': (0,255,255),\n",
        "        'white': (180,180,180)\n",
        "    }\n",
        "\n",
        "    counts = {c:0 for c in color_bgr_map}\n",
        "    vis = img_bgr.copy()\n",
        "\n",
        "    # To exclude colored zones later\n",
        "    combined_color_mask = np.zeros((h,w), np.uint8)\n",
        "\n",
        "    # Process color bricks\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lo, np.uint8), np.array(hi, np.uint8))\n",
        "        base = 'red' if 'red' in name else name\n",
        "        combined_color_mask = cv2.bitwise_or(combined_color_mask, mask)\n",
        "        mask = cv2.medianBlur(mask, 5)\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        bricks = [c for c in cnts if cv2.contourArea(c) > min_area]\n",
        "        counts[base] += len(bricks)\n",
        "        for c in bricks:\n",
        "            x,y,wc,hc = cv2.boundingRect(c)\n",
        "            cv2.rectangle(vis, (x,y), (x+wc,y+hc), color_bgr_map[base], 2)\n",
        "            cv2.putText(vis, base, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base], 1)\n",
        "\n",
        "    # Detect white bricks using edge analysis\n",
        "    white_bricks = detect_white_bricks_on_white_bg(img_bgr, combined_color_mask)\n",
        "    for c in white_bricks:\n",
        "        x,y,wc,hc = cv2.boundingRect(c)\n",
        "        cv2.rectangle(vis, (x,y), (x+wc,y+hc), color_bgr_map['white'], 2)\n",
        "        cv2.putText(vis, 'white', (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50,50,50), 1)\n",
        "    counts['white'] = len(white_bricks)\n",
        "\n",
        "    # Show result\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Detected Bricks (including white on white)\")\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame(sorted(counts.items()), columns=['Color','Num_Bricks'])\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "df = count_and_display_bricks(img)\n",
        "print(df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "K7IKu-IwGF_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY a MASK for each color to ease detection\n",
        "# TRYING TO DETECT ALL BRICKS\n",
        "# SPECIAL TREATMENT FOR WHITE\n",
        "# UNSUCCESSFULL\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def detect_bricks_all_colors(img_bgr, min_area_ratio=0.0003):\n",
        "    \"\"\"\n",
        "    Detects LEGO bricks by color, including white bricks on a white background.\n",
        "    Combines color segmentation + edge-based shape detection.\n",
        "    \"\"\"\n",
        "\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    min_area = int(min_area_ratio * h * w)\n",
        "\n",
        "    # Define HSV color ranges (for colored bricks)\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "    }\n",
        "\n",
        "    color_bgr_map = {\n",
        "        'red': (0, 0, 255),\n",
        "        'blue': (255, 0, 0),\n",
        "        'green': (0, 255, 0),\n",
        "        'yellow': (0, 255, 255),\n",
        "        'white': (180, 180, 180)\n",
        "    }\n",
        "\n",
        "    counts = {c: 0 for c in color_bgr_map}\n",
        "    vis = img_bgr.copy()\n",
        "\n",
        "    # Create a combined mask to exclude colored bricks from white detection\n",
        "    combined_mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "    # --- Step 1: Detect colored bricks ---\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lo, np.uint8), np.array(hi, np.uint8))\n",
        "        base = 'red' if 'red' in name else name\n",
        "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
        "        mask = cv2.medianBlur(mask, 5)\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        bricks = [c for c in cnts if cv2.contourArea(c) > min_area]\n",
        "        counts[base] += len(bricks)\n",
        "        for c in bricks:\n",
        "            x, y, wc, hc = cv2.boundingRect(c)\n",
        "            cv2.rectangle(vis, (x, y), (x + wc, y + hc), color_bgr_map[base], 2)\n",
        "            cv2.putText(vis, base, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base], 1)\n",
        "\n",
        "    # --- Step 2: Detect white bricks using edges ---\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    # Remove colored regions\n",
        "    search_mask = cv2.bitwise_not(combined_mask)\n",
        "    gray_masked = cv2.bitwise_and(gray, gray, mask=search_mask)\n",
        "\n",
        "    # Equalize + blur to enhance contrast\n",
        "    gray_eq = cv2.equalizeHist(gray_masked)\n",
        "    blur = cv2.GaussianBlur(gray_eq, (5, 5), 0)\n",
        "\n",
        "    # Edge detection (low thresholds to pick faint shadows)\n",
        "    edges = cv2.Canny(blur, 20, 80)\n",
        "\n",
        "    # Close small gaps in edges\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, k)\n",
        "\n",
        "    # Find contours (white brick candidates)\n",
        "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    white_bricks = []\n",
        "    for c in cnts:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area <= min_area:\n",
        "            continue\n",
        "        x, y, wc, hc = cv2.boundingRect(c)\n",
        "        rect_area = wc * hc\n",
        "        fill_ratio = area / (rect_area + 1e-6)\n",
        "        aspect = max(wc, hc) / (min(wc, hc) + 1e-6)\n",
        "        # White bricks are rectangular and compact\n",
        "        if 0.6 < fill_ratio < 1.2 and aspect < 3.0:\n",
        "            white_bricks.append(c)\n",
        "\n",
        "    counts['white'] = len(white_bricks)\n",
        "    for c in white_bricks:\n",
        "        x, y, wc, hc = cv2.boundingRect(c)\n",
        "        cv2.rectangle(vis, (x, y), (x + wc, y + hc), color_bgr_map['white'], 2)\n",
        "        cv2.putText(vis, 'white', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "\n",
        "    # --- Step 3: Display ---\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title('Detected Bricks (all colors, including white)')\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame(sorted(counts.items()), columns=['Color', 'Num_Bricks'])\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "df = detect_bricks_all_colors(img)\n",
        "print(df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vRKVYYYbHVMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY a MASK for each color to ease detection\n",
        "# TRYING TO DETECT ALL BRICKS\n",
        "# SPECIAL TREATMENT FOR WHITE\n",
        "# UNSUCCESSFULL\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def detect_white_bricks_adaptive(img_bgr, exclude_mask=None, min_area_ratio=0.0003):\n",
        "    \"\"\"\n",
        "    Detect white LEGO bricks even on a white background using adaptive thresholding.\n",
        "    exclude_mask: binary mask of already-detected colored bricks to ignore.\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = gray.shape\n",
        "    min_area = int(min_area_ratio * h * w)\n",
        "\n",
        "    # Remove colored zones if provided\n",
        "    if exclude_mask is not None:\n",
        "        gray = cv2.bitwise_and(gray, gray, mask=cv2.bitwise_not(exclude_mask))\n",
        "\n",
        "    # Enhance contrast\n",
        "    gray_eq = cv2.equalizeHist(gray)\n",
        "\n",
        "    # --- Adaptive threshold: highlight local dark edges of white bricks ---\n",
        "    th = cv2.adaptiveThreshold(\n",
        "        gray_eq, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,\n",
        "        35,   # blockSize (odd) -> adapt to local lighting\n",
        "        5     # C constant -> adjust sensitivity\n",
        "    )\n",
        "\n",
        "    # Clean up noise\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, k, iterations=1)\n",
        "    th = cv2.morphologyEx(th, cv2.MORPH_OPEN,  k, iterations=1)\n",
        "\n",
        "    cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    white_bricks = []\n",
        "    for c in cnts:\n",
        "        area = cv2.contourArea(c)\n",
        "        if area < min_area:\n",
        "            continue\n",
        "        x, y, wc, hc = cv2.boundingRect(c)\n",
        "        rect_area = wc * hc\n",
        "        fill_ratio = area / (rect_area + 1e-6)\n",
        "        aspect = max(wc, hc) / (min(wc, hc) + 1e-6)\n",
        "        if 0.6 < fill_ratio < 1.1 and 0.7 < aspect < 3.0:\n",
        "            white_bricks.append(c)\n",
        "\n",
        "    return white_bricks\n",
        "\n",
        "\n",
        "def detect_bricks_all_colors(img_bgr):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    min_area = int(0.0003 * h * w)\n",
        "\n",
        "    color_ranges = {\n",
        "        'red1':   [(0, 120, 70), (10, 255, 255)],\n",
        "        'red2':   [(170, 120, 70), (180, 255, 255)],\n",
        "        'blue':   [(90, 80, 50), (130, 255, 255)],\n",
        "        'green':  [(40, 60, 50), (85, 255, 255)],\n",
        "        'yellow': [(20, 100, 100), (35, 255, 255)],\n",
        "    }\n",
        "\n",
        "    color_bgr_map = {\n",
        "        'red': (0, 0, 255),\n",
        "        'blue': (255, 0, 0),\n",
        "        'green': (0, 255, 0),\n",
        "        'yellow': (0, 255, 255),\n",
        "        'white': (180, 180, 180)\n",
        "    }\n",
        "\n",
        "    counts = {c: 0 for c in color_bgr_map}\n",
        "    vis = img_bgr.copy()\n",
        "    combined_mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "    # --- Colored bricks ---\n",
        "    for name, (lo, hi) in color_ranges.items():\n",
        "        mask = cv2.inRange(hsv, np.array(lo, np.uint8), np.array(hi, np.uint8))\n",
        "        base = 'red' if 'red' in name else name\n",
        "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
        "        mask = cv2.medianBlur(mask, 5)\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        bricks = [c for c in cnts if cv2.contourArea(c) > min_area]\n",
        "        counts[base] += len(bricks)\n",
        "        for c in bricks:\n",
        "            x, y, wc, hc = cv2.boundingRect(c)\n",
        "            cv2.rectangle(vis, (x, y), (x + wc, y + hc), color_bgr_map[base], 2)\n",
        "            cv2.putText(vis, base, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr_map[base], 1)\n",
        "\n",
        "    # --- White bricks via adaptive threshold ---\n",
        "    white_bricks = detect_white_bricks_adaptive(img_bgr, combined_mask)\n",
        "    counts['white'] = len(white_bricks)\n",
        "    for c in white_bricks:\n",
        "        x, y, wc, hc = cv2.boundingRect(c)\n",
        "        cv2.rectangle(vis, (x, y), (x + wc, y + hc), color_bgr_map['white'], 2)\n",
        "        cv2.putText(vis, 'white', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
        "\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title('Detected Bricks (including white via adaptive threshold)')\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame(sorted(counts.items()), columns=['Color', 'Num_Bricks'])\n",
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "img = cv2.imread('./data/Isolated/colored_bricks.png')\n",
        "df = detect_bricks_all_colors(img)\n",
        "print(df)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JJwtKhVaH0iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WnuRbAI5mf7"
      },
      "source": [
        "### Area by brick size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE TO DETECT BRICK SIZES\n",
        "# USED STRATEGY FROM BEFORE\n",
        "# FOR EACH IMAGE CREATED ROI USING THE STUDS AND THEN CLUSTER\n",
        "# THE DO BRICK DETECTION LOOKING FOR SPECIFIC SIZES (USING THE STUD)\n",
        "# ALMOST PERFECT - slight error in yellow\n",
        "\n",
        "import os, glob, shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# ======= CONFIG =======\n",
        "PX_PER_MM = 0.330046             # mm per pixel\n",
        "ALLOWED_FILES = {\"blue.png\", \"green.png\", \"red.png\", \"yellow.png\"}\n",
        "VALID_STUD_COUNTS = {2: \"2x1\", 4: \"2x2\", 8: \"4x2\", 12: \"6x2\"}  # exact mapping\n",
        "STUD_MISS_TOL = 1   # allow ¬±1 stud and snap to nearest valid count\n",
        "\n",
        "# ======= UTILS =======\n",
        "def reset_results():\n",
        "    base = \"results\"\n",
        "    if os.path.exists(base):\n",
        "        for item in os.listdir(base):\n",
        "            p = os.path.join(base, item)\n",
        "            try:\n",
        "                if os.path.isfile(p) or os.path.islink(p):\n",
        "                    os.unlink(p)\n",
        "                else:\n",
        "                    shutil.rmtree(p)\n",
        "            except Exception as e:\n",
        "                print(\"‚ö†Ô∏è Delete warning:\", e)\n",
        "    os.makedirs(\"results/annotated\", exist_ok=True)\n",
        "    os.makedirs(\"results/debug\", exist_ok=True)\n",
        "\n",
        "def mm2_from_px_area(px_area: float) -> float:\n",
        "    return float(px_area) * (PX_PER_MM ** 2)\n",
        "\n",
        "def detect_all_studs(img_bgr):\n",
        "    g = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    g = cv2.equalizeHist(g)\n",
        "    g = cv2.medianBlur(g, 3)\n",
        "    # HoughCircles ‚Äì tune if needed\n",
        "    circles = cv2.HoughCircles(\n",
        "        g,\n",
        "        cv2.HOUGH_GRADIENT,\n",
        "        dp=1.2,\n",
        "        minDist=18,\n",
        "        param1=90,\n",
        "        param2=20,            # with 20 it work better than with 15\n",
        "        minRadius=5,\n",
        "        maxRadius=16\n",
        "    )\n",
        "    if circles is None:\n",
        "        return np.empty((0, 2), dtype=np.float32)\n",
        "    C = np.uint16(np.around(circles[0]))\n",
        "    return C[:, :2].astype(np.float32)   # (x,y)\n",
        "\n",
        "def estimate_eps_from_spacing(points):\n",
        "    # Use median nearest-neighbor distance as stud spacing proxy\n",
        "    if len(points) < 2:\n",
        "        return 40.0\n",
        "    from scipy.spatial import cKDTree\n",
        "    tree = cKDTree(points)\n",
        "    dists, _ = tree.query(points, k=2)  # nearest neighbor (k=1 is itself)\n",
        "    nn = np.median(dists[:, 1])\n",
        "    # eps a bit larger than spacing to collect a brick cluster\n",
        "    return float(max(1.25 * nn, 25.0))\n",
        "\n",
        "def boxes_from_stud_clusters(points, labels, margin=10):\n",
        "    rois = []  # list of (x,y,w,h, cluster_id)\n",
        "    for lab in sorted(set(labels)):\n",
        "        if lab == -1:\n",
        "            continue\n",
        "        P = points[labels == lab]\n",
        "        x1, y1 = np.min(P, axis=0)\n",
        "        x2, y2 = np.max(P, axis=0)\n",
        "        x1, y1 = int(x1 - margin), int(y1 - margin)\n",
        "        x2, y2 = int(x2 + margin), int(y2 + margin)\n",
        "        rois.append((x1, y1, max(1, x2 - x1), max(1, y2 - y1), lab))\n",
        "    return rois\n",
        "\n",
        "def remove_overlaps_keep_largest(rois, iou_thresh=0.3, dist_ratio=0.7):\n",
        "    def inter_over_min(a,b):\n",
        "        ax1, ay1, aw, ah = a[:4]; ax2, ay2 = ax1+aw, ay1+ah\n",
        "        bx1, by1, bw, bh = b[:4]; bx2, by2 = bx1+bw, by1+bh\n",
        "        xA, yA = max(ax1,bx1), max(ay1,by1)\n",
        "        xB, yB = min(ax2,bx2), min(ay2,by2)\n",
        "        inter = max(0, xB-xA) * max(0, yB-yA)\n",
        "        areaA, areaB = aw*ah, bw*bh\n",
        "        return inter / float(max(1, min(areaA, areaB)))\n",
        "\n",
        "    def center_dist(a,b):\n",
        "        ax = a[0] + a[2]/2; ay = a[1] + a[3]/2\n",
        "        bx = b[0] + b[2]/2; by = b[1] + b[3]/2\n",
        "        return np.hypot(ax-bx, ay-by)\n",
        "\n",
        "    rois_sorted = sorted(rois, key=lambda r: r[2]*r[3], reverse=True)\n",
        "    keep = []\n",
        "    for r in rois_sorted:\n",
        "        ok = True\n",
        "        for k in keep:\n",
        "            ov = inter_over_min(r,k)\n",
        "            mind = min(r[2], r[3], k[2], k[3])\n",
        "            if ov > 0.25 or center_dist(r,k) < mind * dist_ratio:\n",
        "                ok = False; break\n",
        "        if ok: keep.append(r)\n",
        "    return keep\n",
        "\n",
        "def snap_stud_count(n):\n",
        "    # snap n to nearest in {2,4,8,12} if within ¬±STUD_MISS_TOL; else return None\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))\n",
        "    idx = np.argmin(np.abs(candidates - n))\n",
        "    nearest = int(candidates[idx])\n",
        "    return nearest if abs(nearest - n) <= STUD_MISS_TOL else None\n",
        "\n",
        "def measure_brick_area_in_roi(img_bgr, roi):\n",
        "    x,y,w,h = roi[:4]\n",
        "    crop = img_bgr[max(0,y):y+h, max(0,x):x+w]\n",
        "    if crop.size == 0: return None, None\n",
        "    g = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
        "    # Binary (brick brighter vs background in isolated images). Invert to white-blob.\n",
        "    _, th = cv2.threshold(g, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "    # Fill stud holes so area is footprint\n",
        "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT,(15,15)))\n",
        "    cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not cnts: return None, th\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    return float(cv2.contourArea(c)), th\n",
        "\n",
        "# ======= MAIN PIPELINE =======\n",
        "def process_folder(folder):\n",
        "    reset_results()\n",
        "    per_file_tables = []\n",
        "    all_bricks = []\n",
        "\n",
        "    for path in glob.glob(os.path.join(folder, \"*.png\")):\n",
        "        file = os.path.basename(path)\n",
        "        if file not in ALLOWED_FILES:\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            print(\"‚ö†Ô∏è Cannot read:\", file); continue\n",
        "\n",
        "        # 1) Detect studs globally\n",
        "        studs = detect_all_studs(img)\n",
        "\n",
        "        # If none, skip gracefully\n",
        "        if len(studs) == 0:\n",
        "            print(f\"‚ö†Ô∏è No studs detected in {file}\")\n",
        "            continue\n",
        "\n",
        "        # 2) Cluster studs -> per-brick ROIs\n",
        "        eps = estimate_eps_from_spacing(studs)\n",
        "        labels = DBSCAN(eps=eps, min_samples=2).fit_predict(studs)\n",
        "        rois = boxes_from_stud_clusters(studs, labels, margin=12)\n",
        "        rois = remove_overlaps_keep_largest(rois, iou_thresh=0.3, dist_ratio=0.7)\n",
        "\n",
        "        # 3) For each ROI: count studs (cluster members), classify size, measure area\n",
        "        vis = img.copy()\n",
        "        bricks_rows = []\n",
        "\n",
        "        for (x,y,w,h, lab) in rois:\n",
        "            # studs that belong to this cluster id\n",
        "            studs_in = studs[labels == lab]\n",
        "            n_studs = len(studs_in)\n",
        "\n",
        "            # snap stud count to a valid brick type (2/4/8/12) with tolerance\n",
        "            snapped = snap_stud_count(n_studs)\n",
        "            if snapped is None:\n",
        "                # try a quick local re-detect inside ROI if count way off\n",
        "                crop = img[max(0,y):y+h, max(0,x):x+w]\n",
        "                studs_local = detect_all_studs(crop)\n",
        "                n_studs = len(studs_local)\n",
        "                snapped = snap_stud_count(n_studs)\n",
        "\n",
        "            if snapped is None:\n",
        "                # still unknown ‚Üí skip (or label unknown)\n",
        "                label = \"unknown\"\n",
        "            else:\n",
        "                label = VALID_STUD_COUNTS[snapped]\n",
        "\n",
        "            # measure area from footprint inside ROI\n",
        "            area_px, th = measure_brick_area_in_roi(img, (x,y,w,h))\n",
        "            if area_px is None:\n",
        "                continue\n",
        "            area_mm = mm2_from_px_area(area_px)\n",
        "\n",
        "            # draw annotation\n",
        "            cv2.rectangle(vis, (x,y), (x+w,y+h), (0,255,255), 2)\n",
        "            cv2.putText(vis, f\"{label}\", (x, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "            # draw studs (centers) for this brick\n",
        "            for (sx, sy) in studs[labels == lab]:\n",
        "                cv2.circle(vis, (int(sx), int(sy)), 3, (255,0,0), -1)\n",
        "\n",
        "            bricks_rows.append({\n",
        "                \"File\": file,\n",
        "                \"Size\": label,\n",
        "                \"Studs\": n_studs,\n",
        "                \"Area (pixel)\": area_px,\n",
        "                \"Area (mm¬≤)\": area_mm\n",
        "            })\n",
        "            all_bricks.append(bricks_rows[-1])\n",
        "\n",
        "        # Save annotated image\n",
        "        cv2.imwrite(os.path.join(\"results/annotated\", file), vis)\n",
        "\n",
        "        # 4) Per-file table by size\n",
        "        if bricks_rows:\n",
        "            df_b = pd.DataFrame(bricks_rows)\n",
        "            # keep only valid sizes\n",
        "            df_b = df_b[df_b[\"Size\"].isin(VALID_STUD_COUNTS.values())]\n",
        "            if not df_b.empty:\n",
        "                agg = (df_b.groupby(\"Size\")\n",
        "                        .agg(**{\n",
        "                            \"Number of Bricks\": (\"Area (pixel)\", \"count\"),\n",
        "                            \"Avg Area (pixel)\": (\"Area (pixel)\", \"mean\"),\n",
        "                            \"Avg Area (mm¬≤)\": (\"Area (mm¬≤)\", \"mean\"),\n",
        "                            \"Standard deviation (mm¬≤)\": (\"Area (mm¬≤)\", \"std\"),\n",
        "                        })\n",
        "                        .reset_index())\n",
        "                agg.insert(0, \"File\", file)\n",
        "                per_file_tables.append(agg)\n",
        "\n",
        "        # Optional quick view\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{file} ‚Äî bricks found & labeled\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    # 5) Output tables\n",
        "    # Per-image\n",
        "    if per_file_tables:\n",
        "        df_files = pd.concat(per_file_tables, ignore_index=True)\n",
        "    else:\n",
        "        df_files = pd.DataFrame(columns=[\"File\",\"Size\",\"Number of Bricks\",\"Avg Area (pixel)\",\"Avg Area (mm¬≤)\",\"Standard deviation (mm¬≤)\"])\n",
        "\n",
        "    print(\"\\nüìã Table ‚Äî Per Image (by Size)\")\n",
        "    display(df_files)\n",
        "    df_files.to_csv(\"results/per_image_table.csv\", index=False)\n",
        "\n",
        "    # Global summary\n",
        "    if all_bricks:\n",
        "        df_all = pd.DataFrame(all_bricks)\n",
        "        df_all = df_all[df_all[\"Size\"].isin(VALID_STUD_COUNTS.values())]\n",
        "        if not df_all.empty:\n",
        "            df_summary = (df_all.groupby(\"Size\")\n",
        "                          .agg(**{\n",
        "                              \"Number of Bricks\": (\"Area (pixel)\", \"count\"),\n",
        "                              \"Avg Area (pixel)\": (\"Area (pixel)\", \"mean\"),\n",
        "                              \"Avg Area (mm¬≤)\": (\"Area (mm¬≤)\", \"mean\"),\n",
        "                              \"Standard deviation (mm¬≤)\": (\"Area (mm¬≤)\", \"std\"),\n",
        "                          })\n",
        "                          .reset_index())\n",
        "        else:\n",
        "            df_summary = pd.DataFrame(columns=[\"Size\",\"Number of Bricks\",\"Avg Area (pixel)\",\"Avg Area (mm¬≤)\",\"Standard deviation (mm¬≤)\"])\n",
        "    else:\n",
        "        df_summary = pd.DataFrame(columns=[\"Size\",\"Number of Bricks\",\"Avg Area (pixel)\",\"Avg Area (mm¬≤)\",\"Standard deviation (mm¬≤)\"])\n",
        "\n",
        "    print(\"\\nüìä Table ‚Äî Resume (all images)\")\n",
        "    display(df_summary)\n",
        "    df_summary.to_csv(\"results/resume_table.csv\", index=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Saved:\")\n",
        "    print(\" - results/annotated/<file>.png\")\n",
        "    print(\" - results/per_image_table.csv\")\n",
        "    print(\" - results/resume_table.csv\")\n",
        "\n",
        "# ======= RUN =======\n",
        "process_folder(\"./data/Isolated\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZPCBeemoLlVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE TO DETECT BRICK SIZES\n",
        "# Final refined version: with ROI debug visualization, adjustable EPS + ROI margin, and noise/overlap fixes\n",
        "# Add MAKS method to help identify good studs.\n",
        "# FINAL VERSION\n",
        "\n",
        "import os, glob, shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# ======= CONFIG =======\n",
        "PX_PER_MM = 0.330046\n",
        "ALLOWED_FILES = {\"blue.png\", \"green.png\", \"red.png\", \"yellow.png\"}\n",
        "VALID_STUD_COUNTS = {2: \"2x1\", 4: \"2x2\", 8: \"4x2\", 12: \"6x2\"}\n",
        "STUD_MISS_TOL = 1\n",
        "\n",
        "# üîß Adjustable parameters\n",
        "EPS_MULTIPLIER = 1.23   # controls clustering sensitivity (1.10 = more split, 1.25 = more merge)\n",
        "# 1.23 reveal to be better option to split the ROI\n",
        "\n",
        "ROI_MARGIN = 10         # padding (px) added around each ROI\n",
        "\n",
        "# ======= UTILS =======\n",
        "def reset_results():\n",
        "    base = \"results\"\n",
        "    if os.path.exists(base):\n",
        "        shutil.rmtree(base)\n",
        "    os.makedirs(\"results/annotated\", exist_ok=True)\n",
        "    os.makedirs(\"results/debug\", exist_ok=True)\n",
        "\n",
        "def mm2_from_px_area(px_area):\n",
        "    return float(px_area) * (PX_PER_MM ** 2)\n",
        "\n",
        "def detect_all_studs(img_bgr):\n",
        "    \"\"\"Detect LEGO studs using tuned HoughCircles.\"\"\"\n",
        "    g = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    g = cv2.equalizeHist(g)\n",
        "    g = cv2.medianBlur(g, 3)\n",
        "    circles = cv2.HoughCircles(\n",
        "        g, cv2.HOUGH_GRADIENT, dp=1.2, minDist=18,\n",
        "        param1=90, param2=20, minRadius=5, maxRadius=16\n",
        "    )\n",
        "    if circles is None:\n",
        "        return np.empty((0, 2), dtype=np.float32)\n",
        "    C = np.uint16(np.around(circles[0]))\n",
        "    return C[:, :2].astype(np.float32)\n",
        "\n",
        "def filter_isolated_studs(studs, max_nn_ratio=1.8):\n",
        "    \"\"\"Remove isolated studs far from their nearest neighbor.\"\"\"\n",
        "    if len(studs) < 2:\n",
        "        return studs\n",
        "    tree = cKDTree(studs)\n",
        "    dists, _ = tree.query(studs, k=2)\n",
        "    nn = dists[:, 1]\n",
        "    median_nn = np.median(nn)\n",
        "    mask = nn < (max_nn_ratio * median_nn)\n",
        "    return studs[mask]\n",
        "\n",
        "def estimate_eps_from_spacing(points):\n",
        "    \"\"\"Estimate DBSCAN eps from stud spacing.\"\"\"\n",
        "    if len(points) < 2:\n",
        "        return 40.0\n",
        "    tree = cKDTree(points)\n",
        "    dists, _ = tree.query(points, k=2)\n",
        "    nn = np.median(dists[:, 1])\n",
        "    return float(max(EPS_MULTIPLIER * nn, 25.0))\n",
        "\n",
        "def boxes_from_stud_clusters(points, labels, margin=ROI_MARGIN):\n",
        "    \"\"\"Create ROIs (bounding boxes) from clustered studs.\"\"\"\n",
        "    rois = []\n",
        "    for lab in sorted(set(labels)):\n",
        "        if lab == -1: continue\n",
        "        P = points[labels == lab]\n",
        "        x1, y1 = np.min(P, axis=0)\n",
        "        x2, y2 = np.max(P, axis=0)\n",
        "        x1, y1 = int(x1 - margin), int(y1 - margin)\n",
        "        x2, y2 = int(x2 + margin), int(y2 + margin)\n",
        "        rois.append((x1, y1, max(1, x2 - x1), max(1, y2 - y1), lab))\n",
        "    return rois\n",
        "\n",
        "def remove_overlaps_keep_largest(rois, iou_thresh=0.4, dist_ratio=0.6):\n",
        "    \"\"\"Gentle overlap filtering to preserve small bricks.\"\"\"\n",
        "    def inter_over_min(a,b):\n",
        "        ax1,ay1,aw,ah=a[:4]; bx1,by1,bw,bh=b[:4]\n",
        "        ax2,ay2=ax1+aw,ay1+ah; bx2,by2=bx1+bw,by1+bh\n",
        "        xA,yA=max(ax1,bx1),max(ay1,by1)\n",
        "        xB,yB=min(ax2,bx2),min(ay2,by2)\n",
        "        inter=max(0,xB-xA)*max(0,yB-yA)\n",
        "        areaA,areaB=aw*ah,bw*bh\n",
        "        return inter/max(1,min(areaA,areaB))\n",
        "    def center_dist(a,b):\n",
        "        ax,ay=a[0]+a[2]/2,a[1]+a[3]/2\n",
        "        bx,by=b[0]+b[2]/2,b[1]+b[3]/2\n",
        "        return np.hypot(ax-bx,ay-by)\n",
        "    keep=[]\n",
        "    for r in sorted(rois,key=lambda x:x[2]*x[3],reverse=True):\n",
        "        if all(not (inter_over_min(r,k)>iou_thresh and center_dist(r,k)<min(r[2],r[3],k[2],k[3])*dist_ratio) for k in keep):\n",
        "            keep.append(r)\n",
        "    return keep\n",
        "'''\n",
        "def snap_stud_count(n):\n",
        "    \"\"\"Snap stud count to valid size (2,4,8,12).\"\"\"\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))\n",
        "    idx = np.argmin(np.abs(candidates - n))\n",
        "    nearest = int(candidates[idx])\n",
        "    return nearest if abs(nearest - n) <= STUD_MISS_TOL else None\n",
        "'''\n",
        "\n",
        "def snap_stud_count(n):\n",
        "    \"\"\"\n",
        "    Snap stud count to nearest valid size (2, 4, 8, 12)\n",
        "    with ¬±STUD_MISS_TOL tolerance, preferring upward snaps on ties.\n",
        "    \"\"\"\n",
        "    n = int(n)\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))  # [2, 4, 8, 12]\n",
        "    diffs = np.abs(candidates - n)\n",
        "    min_diff = diffs.min()\n",
        "\n",
        "    # candidates with same min difference\n",
        "    nearest_candidates = candidates[diffs == min_diff]\n",
        "    # prefer larger when tied\n",
        "    nearest = int(nearest_candidates.max())\n",
        "\n",
        "    if abs(nearest - n) <= STUD_MISS_TOL:\n",
        "        return nearest\n",
        "    return None\n",
        "\n",
        "def measure_brick_area_in_roi(img_bgr, roi):\n",
        "    \"\"\"Measure the area of the brick footprint inside an ROI.\"\"\"\n",
        "    x,y,w,h = roi[:4]\n",
        "    crop = img_bgr[max(0,y):y+h, max(0,x):x+w]\n",
        "    if crop.size == 0:\n",
        "        return None, None\n",
        "    g = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
        "    _, th = cv2.threshold(g, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT,(15,15)))\n",
        "    cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not cnts:\n",
        "        return None, th\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    return float(cv2.contourArea(c)), th\n",
        "\n",
        "# NEW FUNCTION THAT I SUGEST TO ADD\n",
        "def remove_too_close_studs(studs, min_dist=8):\n",
        "    \"\"\"\n",
        "    Removes duplicate or overlapping stud detections.\n",
        "    Keeps only one stud from each pair that are closer than min_dist pixels.\n",
        "    \"\"\"\n",
        "    if len(studs) < 3:\n",
        "        return studs\n",
        "    keep = []\n",
        "    used = np.zeros(len(studs), dtype=bool)\n",
        "    for i in range(len(studs)):\n",
        "        if used[i]:\n",
        "            continue\n",
        "        keep.append(studs[i])\n",
        "        for j in range(i + 1, len(studs)):\n",
        "            if np.linalg.norm(studs[i] - studs[j]) < min_dist:\n",
        "                used[j] = True\n",
        "    return np.array(keep, dtype=np.float32)\n",
        "\n",
        "# ANOTHER NEW FUNCTION\n",
        "\n",
        "def keep_colored_studs(img_bgr, studs, sat_thresh=60, val_min=50, val_max=240):\n",
        "    \"\"\"\n",
        "    Keeps only studs located over sufficiently colored (non-white) pixels.\n",
        "    Filters out studs over low-saturation or near-white background areas.\n",
        "    \"\"\"\n",
        "    if len(studs) == 0:\n",
        "        return studs\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    kept = []\n",
        "    for (x, y) in studs:\n",
        "        x = int(round(x))\n",
        "        y = int(round(y))\n",
        "        if y < 0 or y >= hsv.shape[0] or x < 0 or x >= hsv.shape[1]:\n",
        "            continue\n",
        "        h, s, v = hsv[y, x]\n",
        "        # keep studs with decent saturation and not too bright\n",
        "        if s > sat_thresh and val_min < v < val_max:\n",
        "            kept.append([x, y])\n",
        "    return np.array(kept, dtype=np.float32)\n",
        "\n",
        "def studs_inside_edges(img_bgr, studs, roi, canny1=70, canny2=150):\n",
        "    \"\"\"\n",
        "    Returns only the studs whose centers fall inside the main edge contour\n",
        "    of the brick within the given ROI.\n",
        "    \"\"\"\n",
        "    x, y, w, h = roi[:4]\n",
        "    crop = img_bgr[max(0,y):y+h, max(0,x):x+w]\n",
        "    if crop.size == 0 or len(studs) == 0:\n",
        "        return studs\n",
        "\n",
        "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
        "    #edges = cv2.Canny(gray, canny1, canny2)\n",
        "\n",
        "    # compute median intensity in ROI\n",
        "    med_val = np.median(gray)\n",
        "    sigma = 0.33\n",
        "    low = int(max(0, (1.0 - sigma) * med_val))\n",
        "    high = int(min(255, (1.0 + sigma) * med_val))\n",
        "    edges = cv2.Canny(gray, low, high)\n",
        "\n",
        "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not cnts:\n",
        "        return studs\n",
        "\n",
        "    # Take the largest contour as the brick boundary\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "    # Convert studs from global to local ROI coordinates\n",
        "    studs_local = studs - np.array([x, y], dtype=np.float32)\n",
        "\n",
        "    kept = []\n",
        "    for (sx, sy) in studs_local:\n",
        "        inside = cv2.pointPolygonTest(c, (float(sx), float(sy)), measureDist=False)\n",
        "        if inside >= 0:   # >=0 means point inside or on edge\n",
        "            kept.append([sx + x, sy + y])  # convert back to global coords\n",
        "    return np.array(kept, dtype=np.float32)\n",
        "\n",
        "def make_color_mask(img_bgr, color):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    if color == 'yellow':\n",
        "        lower, upper = (10, 100, 100), (35, 255, 255)\n",
        "    elif color == 'red':\n",
        "        lower1, upper1 = (0, 120, 70), (10, 255, 255)\n",
        "        lower2, upper2 = (170, 120, 70), (180, 255, 255)\n",
        "        mask = cv2.inRange(hsv, np.array(lower1), np.array(upper1)) | cv2.inRange(hsv, np.array(lower2), np.array(upper2))\n",
        "        return mask\n",
        "    elif color == 'blue':\n",
        "        lower, upper = (90, 80, 50), (130, 255, 255)\n",
        "    elif color == 'green':\n",
        "        lower, upper = (40, 60, 50), (85, 255, 255)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown color: {color}\")\n",
        "\n",
        "    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((9,9), np.uint8))\n",
        "    return mask\n",
        "\n",
        "def keep_studs_inside_mask(studs, mask):\n",
        "    h, w = mask.shape\n",
        "    kept = []\n",
        "    for (x, y) in studs:\n",
        "        xi, yi = int(round(x)), int(round(y))\n",
        "        if 0 <= xi < w and 0 <= yi < h and mask[yi, xi] > 0:\n",
        "            kept.append([x, y])\n",
        "    return np.array(kept, dtype=np.float32)\n",
        "\n",
        "\n",
        "# ======= MAIN PIPELINE =======\n",
        "def process_folder(folder):\n",
        "    reset_results()\n",
        "    per_file_tables, all_bricks = [], []\n",
        "\n",
        "    for path in glob.glob(os.path.join(folder, \"*.png\")):\n",
        "        file = os.path.basename(path)\n",
        "        if file not in ALLOWED_FILES:\n",
        "            continue\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        # Extract color name from file (e.g., \"blue.png\" ‚Üí \"blue\")\n",
        "        color_name = os.path.splitext(file)[0].lower()\n",
        "\n",
        "        # --- Detect & clean studs ---\n",
        "\n",
        "        studs = detect_all_studs(img)\n",
        "\n",
        "        # Remove studs over non-colored (white/gray) areas\n",
        "        #studs = keep_colored_studs(img, studs, sat_thresh=40, val_min=40, val_max=250)\n",
        "        # commented: this is no longer necessary - using the mask make the removal of the noise studs redundant\n",
        "\n",
        "        # Build color mask for this brick color\n",
        "        mask = make_color_mask(img, color=color_name)\n",
        "\n",
        "        # Keep only studs inside mask region\n",
        "        studs = keep_studs_inside_mask(studs, mask)\n",
        "\n",
        "        # Optional: also remove near-duplicate studs\n",
        "        studs = remove_too_close_studs(studs, min_dist=30)\n",
        "        # This is important to correct classification - help removing noisy studs\n",
        "\n",
        "        # Remove very isolated ones\n",
        "        #studs = filter_isolated_studs(studs)\n",
        "        # commented: this is no longer necessary - using the mask make the removal of the noise studs redundant\n",
        "\n",
        "        if len(studs) == 0:\n",
        "            print(f\"‚ö†Ô∏è No studs in {file}\")\n",
        "            continue\n",
        "\n",
        "        # --- Cluster studs ---\n",
        "        eps = estimate_eps_from_spacing(studs)\n",
        "        labels = DBSCAN(eps=eps, min_samples=2).fit_predict(studs)\n",
        "        rois = boxes_from_stud_clusters(studs, labels)\n",
        "        rois = remove_overlaps_keep_largest(rois)\n",
        "\n",
        "        # --- ROI DEBUG VISUALIZATION ---\n",
        "        dbg = img.copy()\n",
        "        for i, (x,y,w,h,lab) in enumerate(rois, start=1):\n",
        "            cv2.rectangle(dbg, (x,y), (x+w,y+h), (0,0,255), 2)\n",
        "            cv2.putText(dbg, f\"ROI {i}\", (x, y-5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "        for (sx,sy) in studs:\n",
        "            cv2.circle(dbg, (int(sx), int(sy)), 3, (255,0,0), -1)\n",
        "        cv2.imwrite(f\"results/debug/{os.path.splitext(file)[0]}_rois.png\", dbg)\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{file} ‚Äî ROI Debug (red boxes = clusters, blue dots = studs)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # --- Brick Classification and Area ---\n",
        "        vis = img.copy()\n",
        "        bricks_rows = []\n",
        "\n",
        "        for (x,y,w,h,lab) in rois:\n",
        "            studs_in = studs[labels == lab]\n",
        "\n",
        "            # ADD NEW CODE - edges\n",
        "            #studs_in = studs_inside_edges(img, studs_in, (x, y, w, h))\n",
        "            # END OF ADD CODE\n",
        "\n",
        "            n_studs = len(studs_in)\n",
        "            snapped = snap_stud_count(n_studs)\n",
        "\n",
        "            if snapped is None:\n",
        "                crop = img[max(0,y):y+h, max(0,x):x+w]\n",
        "                studs_local = detect_all_studs(crop)\n",
        "                studs_local = filter_isolated_studs(studs_local)\n",
        "                n_studs = len(studs_local)\n",
        "                snapped = snap_stud_count(n_studs)\n",
        "\n",
        "            label = VALID_STUD_COUNTS.get(snapped, \"unknown\")\n",
        "            area_px, th = measure_brick_area_in_roi(img, (x,y,w,h))\n",
        "            if area_px is None:\n",
        "                continue\n",
        "            area_mm = mm2_from_px_area(area_px)\n",
        "\n",
        "            cv2.rectangle(vis, (x,y), (x+w,y+h), (0,255,255), 2)\n",
        "            cv2.putText(vis, label, (x, y-6),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "            for (sx,sy) in studs_in:\n",
        "                cv2.circle(vis, (int(sx), int(sy)), 3, (255,0,0), -1)\n",
        "\n",
        "            bricks_rows.append({\n",
        "                \"File\": file,\n",
        "                \"Size\": label,\n",
        "                \"Studs\": n_studs,\n",
        "                \"Area (pixel)\": area_px,\n",
        "                \"Area (mm¬≤)\": area_mm\n",
        "            })\n",
        "            all_bricks.append(bricks_rows[-1])\n",
        "\n",
        "        cv2.imwrite(os.path.join(\"results/annotated\", file), vis)\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{file} ‚Äî Bricks Labeled (yellow boxes)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # --- Per-file Summary ---\n",
        "        if bricks_rows:\n",
        "            df_b = pd.DataFrame(bricks_rows)\n",
        "            df_b = df_b[df_b[\"Size\"].isin(VALID_STUD_COUNTS.values())]\n",
        "            if not df_b.empty:\n",
        "                agg = (df_b.groupby(\"Size\")\n",
        "                        .agg(**{\n",
        "                            \"Number of Bricks\": (\"Area (pixel)\", \"count\"),\n",
        "                            \"Avg Area (pixel)\": (\"Area (pixel)\", \"mean\"),\n",
        "                            \"Avg Area (mm¬≤)\": (\"Area (mm¬≤)\", \"mean\"),\n",
        "                            \"Standard deviation (mm¬≤)\": (\"Area (mm¬≤)\", \"std\")\n",
        "                        })\n",
        "                        .reset_index())\n",
        "                agg.insert(0, \"File\", file)\n",
        "                per_file_tables.append(agg)\n",
        "\n",
        "    # --- Tables ---\n",
        "    df_files = pd.concat(per_file_tables, ignore_index=True) if per_file_tables else pd.DataFrame()\n",
        "    print(\"\\nüìã Table ‚Äî Per Image (by Size)\")\n",
        "    display(df_files)\n",
        "    df_files.to_csv(\"results/per_image_table.csv\", index=False)\n",
        "\n",
        "    if all_bricks:\n",
        "        df_all = pd.DataFrame(all_bricks)\n",
        "        df_all = df_all[df_all[\"Size\"].isin(VALID_STUD_COUNTS.values())]\n",
        "        df_summary = (df_all.groupby(\"Size\")\n",
        "                      .agg(**{\n",
        "                          \"Number of Bricks\": (\"Area (pixel)\", \"count\"),\n",
        "                          \"Avg Area (pixel)\": (\"Area (pixel)\", \"mean\"),\n",
        "                          \"Avg Area (mm¬≤)\": (\"Area (mm¬≤)\", \"mean\"),\n",
        "                          \"Standard deviation (mm¬≤)\": (\"Area (mm¬≤)\", \"std\")\n",
        "                      })\n",
        "                      .reset_index())\n",
        "    else:\n",
        "        df_summary = pd.DataFrame()\n",
        "\n",
        "    print(\"\\nüìä Table ‚Äî Resume (all images)\")\n",
        "    display(df_summary)\n",
        "    df_summary.to_csv(\"results/resume_table.csv\", index=False)\n",
        "    print(f\"\\n‚úÖ Done with EPS_MULTIPLIER={EPS_MULTIPLIER}, ROI_MARGIN={ROI_MARGIN}\")\n",
        "    print(\"   Results saved to results/annotated/ and results/debug/\")\n",
        "\n",
        "# ======= RUN =======\n",
        "process_folder(\"./data/Isolated\")\n"
      ],
      "metadata": {
        "id": "lS-Y2SHjDHFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 2c)\n",
        "\n",
        "Previous code show all the bricks being counted by format.\n"
      ],
      "metadata": {
        "id": "twVgech5PEGp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ0A_XW75mf7"
      },
      "source": [
        "## 3Ô∏è‚É£ Kit Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeuiMl095mf7"
      },
      "source": [
        "### Count bricks by color per kit (kit 1, 2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEGO Kit Brick Detection (Multi-color version)\n",
        "# Based on your final refined \"Isolated\" pipeline ‚Äî adapted for Kit images\n",
        "\n",
        "import os, glob, shutil, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# ======= CONFIG =======\n",
        "PX_PER_MM = 0.330046\n",
        "VALID_STUD_COUNTS = {2: \"2x1\", 4: \"2x2\", 8: \"4x2\", 12: \"6x2\"}\n",
        "STUD_MISS_TOL = 1\n",
        "EPS_MULTIPLIER = 1.23\n",
        "ROI_MARGIN = 10\n",
        "COLORS = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
        "\n",
        "# ======= UTILS =======\n",
        "def reset_results():\n",
        "    base = \"results\"\n",
        "    if os.path.exists(base):\n",
        "        shutil.rmtree(base)\n",
        "    os.makedirs(\"results/annotated\", exist_ok=True)\n",
        "    os.makedirs(\"results/debug\", exist_ok=True)\n",
        "\n",
        "def mm2_from_px_area(px_area):\n",
        "    return float(px_area) * (PX_PER_MM ** 2)\n",
        "'''\n",
        "def detect_all_studs(img_bgr):\n",
        "    g = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    g = cv2.equalizeHist(g)\n",
        "    g = cv2.medianBlur(g, 3)\n",
        "    circles = cv2.HoughCircles(\n",
        "        g, cv2.HOUGH_GRADIENT, dp=1.2, minDist=18,\n",
        "        param1=90, param2=20, minRadius=5, maxRadius=16\n",
        "    )\n",
        "    if circles is None:\n",
        "        return np.empty((0, 2), dtype=np.float32)\n",
        "    C = np.uint16(np.around(circles[0]))\n",
        "    return C[:, :2].astype(np.float32)\n",
        "'''\n",
        "\n",
        "def detect_all_studs(img_bgr, color_hint=None):\n",
        "    \"\"\"\n",
        "    Detect LEGO studs using tuned HoughCircles, adaptive per color_hint.\n",
        "    color_hint can be one of: 'red', 'yellow', 'green', 'blue', 'white', or None.\n",
        "    \"\"\"\n",
        "\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "    gray = cv2.medianBlur(gray, 3)\n",
        "\n",
        "    # --- Default parameters ---\n",
        "    param1 = 90   # upper threshold for edge detection\n",
        "    param2 = 20   # accumulator threshold (lower ‚Üí more circles)\n",
        "    minR, maxR = 5, 16\n",
        "\n",
        "    # --- Adjust based on color ---\n",
        "    if color_hint == 'red':\n",
        "        param2 = 17   # more sensitive\n",
        "    elif color_hint == 'yellow':\n",
        "        param2 = 18   # stricter (avoid false positives) 23\n",
        "        param1 = 80   # was 100 com 80 melhorou\n",
        "    elif color_hint == 'green':\n",
        "        param2 = 20\n",
        "    elif color_hint == 'blue':\n",
        "        param2 = 20\n",
        "    elif color_hint == 'white':\n",
        "        param2 = 22\n",
        "\n",
        "    circles = cv2.HoughCircles(\n",
        "        gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=18,\n",
        "        param1=param1, param2=param2,\n",
        "        minRadius=minR, maxRadius=maxR\n",
        "    )\n",
        "\n",
        "    if circles is None:\n",
        "        return np.empty((0, 2), dtype=np.float32)\n",
        "\n",
        "    C = np.uint16(np.around(circles[0]))\n",
        "    return C[:, :2].astype(np.float32)\n",
        "\n",
        "def remove_too_close_studs(studs, min_dist=8):\n",
        "    if len(studs) < 3: return studs\n",
        "    keep = []\n",
        "    used = np.zeros(len(studs), dtype=bool)\n",
        "    for i in range(len(studs)):\n",
        "        if used[i]: continue\n",
        "        keep.append(studs[i])\n",
        "        for j in range(i+1, len(studs)):\n",
        "            if np.linalg.norm(studs[i]-studs[j]) < min_dist:\n",
        "                used[j] = True\n",
        "    return np.array(keep, dtype=np.float32)\n",
        "\n",
        "def estimate_eps_from_spacing(points):\n",
        "    if len(points) < 2: return 40.0\n",
        "    tree = cKDTree(points)\n",
        "    dists, _ = tree.query(points, k=2)\n",
        "    nn = np.median(dists[:, 1])\n",
        "    return float(max(EPS_MULTIPLIER * nn, 25.0))\n",
        "\n",
        "def boxes_from_stud_clusters(points, labels, margin=ROI_MARGIN):\n",
        "    rois = []\n",
        "    for lab in sorted(set(labels)):\n",
        "        if lab == -1: continue\n",
        "        P = points[labels == lab]\n",
        "        x1, y1 = np.min(P, axis=0)\n",
        "        x2, y2 = np.max(P, axis=0)\n",
        "        x1, y1 = int(x1 - margin), int(y1 - margin)\n",
        "        x2, y2 = int(x2 + margin), int(y2 + margin)\n",
        "        rois.append((x1, y1, max(1,x2-x1), max(1,y2-y1), lab))\n",
        "    return rois\n",
        "\n",
        "def remove_overlaps_keep_largest(rois, iou_thresh=0.4, dist_ratio=0.6):\n",
        "    \"\"\"Gentle overlap filtering to preserve small bricks.\"\"\"\n",
        "    def inter_over_min(a, b):\n",
        "        ax1, ay1, aw, ah = a[:4]\n",
        "        bx1, by1, bw, bh = b[:4]\n",
        "        ax2, ay2 = ax1 + aw, ay1 + ah\n",
        "        bx2, by2 = bx1 + bw, by1 + bh\n",
        "        xA, yA = max(ax1, bx1), max(ay1, by1)\n",
        "        xB, yB = min(ax2, bx2), min(ay2, by2)\n",
        "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
        "        areaA, areaB = aw * ah, bw * bh\n",
        "        return inter / max(1, min(areaA, areaB))\n",
        "\n",
        "    keep = []\n",
        "    # Sort by area descending ‚Äî keep bigger first\n",
        "    for r in sorted(rois, key=lambda x: x[2] * x[3], reverse=True):\n",
        "        if all(inter_over_min(r, k) < iou_thresh for k in keep):\n",
        "            keep.append(r)\n",
        "    return keep\n",
        "'''\n",
        "def snap_stud_count(n):\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))\n",
        "    idx = np.argmin(np.abs(candidates - n))\n",
        "    nearest = int(candidates[idx])\n",
        "    return nearest if abs(nearest - n) <= STUD_MISS_TOL else None\n",
        "'''\n",
        "def snap_stud_count(n):\n",
        "    \"\"\"\n",
        "    Snap stud count to nearest valid size (2, 4, 8, 12)\n",
        "    with ¬±STUD_MISS_TOL tolerance, preferring upward snaps on ties.\n",
        "    \"\"\"\n",
        "    n = int(n)\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))  # [2, 4, 8, 12]\n",
        "    diffs = np.abs(candidates - n)\n",
        "    min_diff = diffs.min()\n",
        "\n",
        "    # candidates with same min difference\n",
        "    nearest_candidates = candidates[diffs == min_diff]\n",
        "    # prefer larger when tied\n",
        "    nearest = int(nearest_candidates.max())\n",
        "\n",
        "    if abs(nearest - n) <= STUD_MISS_TOL:\n",
        "        return nearest\n",
        "    return None\n",
        "\n",
        "\n",
        "def make_color_mask(img_bgr, color):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    if color == \"yellow\":\n",
        "        lower, upper = (10, 100, 100), (35, 255, 255)\n",
        "    elif color == \"red\":\n",
        "        lower1, upper1 = (0, 120, 70), (10, 255, 255)\n",
        "        lower2, upper2 = (170, 120, 70), (180, 255, 255)\n",
        "        return (cv2.inRange(hsv, np.array(lower1), np.array(upper1)) |\n",
        "                cv2.inRange(hsv, np.array(lower2), np.array(upper2)))\n",
        "    elif color == \"blue\":\n",
        "        lower, upper = (90, 80, 50), (130, 255, 255)\n",
        "    elif color == \"green\":\n",
        "        lower, upper = (40, 60, 50), (85, 255, 255)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown color: {color}\")\n",
        "    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((9,9), np.uint8))\n",
        "    return mask\n",
        "\n",
        "def keep_studs_inside_mask(studs, mask):\n",
        "    h, w = mask.shape\n",
        "    kept = []\n",
        "    for (x, y) in studs:\n",
        "        xi, yi = int(round(x)), int(round(y))\n",
        "        if 0 <= xi < w and 0 <= yi < h and mask[yi, xi] > 0:\n",
        "            kept.append([x, y])\n",
        "    return np.array(kept, dtype=np.float32)\n",
        "\n",
        "# ======= MAIN =======\n",
        "\n",
        "def process_kits(folder=\"./data/Kit\"):\n",
        "\n",
        "    reset_results()\n",
        "    all_rows = []\n",
        "    for kit_path in sorted(glob.glob(os.path.join(folder, \"kit*.png\"))):\n",
        "\n",
        "        name = os.path.basename(kit_path)\n",
        "        print(f\"\\nüîπ Processing {name}\")\n",
        "        img = cv2.imread(kit_path)\n",
        "        dbg, vis = img.copy(), img.copy()\n",
        "        roi_id = 1\n",
        "\n",
        "        for color in COLORS:\n",
        "            mask = make_color_mask(img, color)\n",
        "            #studs = detect_all_studs(img)\n",
        "            studs = detect_all_studs(img, color_hint=color)\n",
        "            studs = keep_studs_inside_mask(studs, mask)\n",
        "            studs = remove_too_close_studs(studs, min_dist=30)\n",
        "            if len(studs)==0:\n",
        "                continue\n",
        "\n",
        "            eps = estimate_eps_from_spacing(studs)\n",
        "            labels = DBSCAN(eps=eps, min_samples=2).fit_predict(studs)\n",
        "            rois = boxes_from_stud_clusters(studs, labels)\n",
        "            rois = remove_overlaps_keep_largest(rois)\n",
        "\n",
        "            for (x,y,w,h,lab) in rois:\n",
        "                studs_in = studs[labels==lab]\n",
        "                n_studs = len(studs_in)\n",
        "                snapped = snap_stud_count(n_studs)\n",
        "                label = VALID_STUD_COUNTS.get(snapped, \"unknown\")\n",
        "\n",
        "                cv2.rectangle(dbg,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "                cv2.putText(dbg,f\"ROI {roi_id}\",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
        "                for (sx,sy) in studs_in:\n",
        "                    cv2.circle(dbg,(int(sx),int(sy)),3,(255,0,0),-1)\n",
        "                roi_id+=1\n",
        "\n",
        "                cv2.rectangle(vis,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "                cv2.putText(vis,f\"{color} {label}\",(x,y-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
        "\n",
        "                # --- Draw centroid in black ---\n",
        "                cx, cy = int(x + w / 2), int(y + h / 2)\n",
        "                cv2.circle(dbg, (cx, cy), 4, (0, 0, 0), -1)\n",
        "                cv2.circle(vis, (cx, cy), 4, (0, 0, 0), -1)\n",
        "\n",
        "\n",
        "                all_rows.append({\"Kit\":name,\"Color\":color,\"Size\":label,\"Studs\":n_studs})\n",
        "\n",
        "        # Save and show debug views\n",
        "        cv2.imwrite(f\"results/debug/{name}_rois.png\", dbg)\n",
        "        cv2.imwrite(f\"results/annotated/{name}_bricks.png\", vis)\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî ROI Debug (red boxes = clusters, blue dots = studs)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî Bricks Labeled (yellow boxes)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # ===== Pretty summary print: kit name & format shown only once per group =====\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "\n",
        "        # Aggregate results\n",
        "        summary = (\n",
        "            df.groupby([\"Kit\", \"Size\", \"Color\"])\n",
        "              .size()\n",
        "              .reset_index(name=\"quantity\")\n",
        "              .sort_values([\"Kit\", \"Size\", \"Color\"])\n",
        "        )\n",
        "\n",
        "        print(\"\\nüìä Final Results ‚Äî Bricks per Kit\\n\")\n",
        "\n",
        "        pretty_blocks = []\n",
        "        for kit_name, sub in summary.groupby(\"Kit\", sort=False):\n",
        "            sub = sub.copy()\n",
        "            # Rename columns only once\n",
        "            sub = sub.rename(columns={\"Kit\": \"kit name\", \"Size\": \"format\", \"Color\": \"color\"})\n",
        "\n",
        "            # Make 'kit name' column blank except for first row\n",
        "            sub.loc[sub.index[0], \"kit name\"] = kit_name\n",
        "            sub.loc[sub.index[1]:, \"kit name\"] = \"\"\n",
        "\n",
        "            # Remove repeated formats within the same kit\n",
        "            last_fmt = None\n",
        "            for i in sub.index:\n",
        "                fmt = sub.at[i, \"format\"]\n",
        "                if fmt == last_fmt:\n",
        "                    sub.at[i, \"format\"] = \"\"\n",
        "                else:\n",
        "                    last_fmt = fmt\n",
        "\n",
        "            pretty_blocks.append(sub[[\"kit name\", \"format\", \"color\", \"quantity\"]])\n",
        "\n",
        "        pretty_summary = pd.concat(pretty_blocks, ignore_index=True)\n",
        "\n",
        "        # Display neatly without index column\n",
        "        display(pretty_summary.style.hide(axis=\"index\"))\n",
        "\n",
        "        # Save full detailed CSV (with all values)\n",
        "        summary.to_csv(\"results/kit_summary.csv\", index=False)\n",
        "        print(\"‚úÖ Summary saved to results/kit_summary.csv\")\n",
        "    else:\n",
        "        print(\"No results to summarize.\")\n",
        "\n",
        "# ======= RUN =======\n",
        "process_kits()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b4usydDTV9kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 3a) and 3b)\n",
        "\n",
        "Previous code show for each kit the quantity by format and color.\n",
        "Displays the detection of each brick with the centroid for each brick in black."
      ],
      "metadata": {
        "id": "e1PP8aPZYC8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESS ALL KIT IN FOLDER\n",
        "# SEPARATE REFERENCE KITS FROM TESTING ONES\n",
        "# EVALUATE SIMILARITY\n",
        "\n",
        "def process_all_kits(folder=\"./data/Kit\"):\n",
        "\n",
        "    reset_results()\n",
        "    all_rows = []\n",
        "    for kit_path in sorted(glob.glob(os.path.join(folder, \"*.png\"))):\n",
        "\n",
        "        name = os.path.basename(kit_path)\n",
        "        print(f\"\\nüîπ Processing {name}\")\n",
        "        img = cv2.imread(kit_path)\n",
        "        dbg, vis = img.copy(), img.copy()\n",
        "        roi_id = 1\n",
        "\n",
        "        for color in COLORS:\n",
        "            mask = make_color_mask(img, color)\n",
        "            #studs = detect_all_studs(img)\n",
        "            studs = detect_all_studs(img, color_hint=color)\n",
        "            studs = keep_studs_inside_mask(studs, mask)\n",
        "            studs = remove_too_close_studs(studs, min_dist=30)\n",
        "            if len(studs)==0:\n",
        "                continue\n",
        "\n",
        "            eps = estimate_eps_from_spacing(studs)\n",
        "            labels = DBSCAN(eps=eps, min_samples=2).fit_predict(studs)\n",
        "            rois = boxes_from_stud_clusters(studs, labels)\n",
        "            rois = remove_overlaps_keep_largest(rois)\n",
        "\n",
        "            for (x,y,w,h,lab) in rois:\n",
        "                studs_in = studs[labels==lab]\n",
        "                n_studs = len(studs_in)\n",
        "                snapped = snap_stud_count(n_studs)\n",
        "                label = VALID_STUD_COUNTS.get(snapped, \"unknown\")\n",
        "\n",
        "                cv2.rectangle(dbg,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "                cv2.putText(dbg,f\"ROI {roi_id}\",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
        "                for (sx,sy) in studs_in:\n",
        "                    cv2.circle(dbg,(int(sx),int(sy)),3,(255,0,0),-1)\n",
        "                roi_id+=1\n",
        "\n",
        "                cv2.rectangle(vis,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "                cv2.putText(vis,f\"{color} {label}\",(x,y-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
        "\n",
        "                # --- Draw centroid in black ---\n",
        "                cx, cy = int(x + w / 2), int(y + h / 2)\n",
        "                cv2.circle(dbg, (cx, cy), 4, (0, 0, 0), -1)\n",
        "                cv2.circle(vis, (cx, cy), 4, (0, 0, 0), -1)\n",
        "\n",
        "\n",
        "                all_rows.append({\"Kit\":name,\"Color\":color,\"Size\":label,\"Studs\":n_studs})\n",
        "\n",
        "        # Save and show debug views\n",
        "        cv2.imwrite(f\"results/debug/{name}_rois.png\", dbg)\n",
        "        cv2.imwrite(f\"results/annotated/{name}_bricks.png\", vis)\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî ROI Debug (red boxes = clusters, blue dots = studs)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî Bricks Labeled (yellow boxes)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # ===== Pretty summary print: kit name & format shown only once per group =====\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "\n",
        "        # Aggregate results\n",
        "        summary = (\n",
        "            df.groupby([\"Kit\", \"Size\", \"Color\"])\n",
        "              .size()\n",
        "              .reset_index(name=\"quantity\")\n",
        "              .sort_values([\"Kit\", \"Size\", \"Color\"])\n",
        "        )\n",
        "\n",
        "        print(\"\\nüìä Final Results ‚Äî Bricks per Kit\\n\")\n",
        "\n",
        "        pretty_blocks = []\n",
        "        for kit_name, sub in summary.groupby(\"Kit\", sort=False):\n",
        "            sub = sub.copy()\n",
        "            # Rename columns only once\n",
        "            sub = sub.rename(columns={\"Kit\": \"kit name\", \"Size\": \"format\", \"Color\": \"color\"})\n",
        "\n",
        "            # Make 'kit name' column blank except for first row\n",
        "            sub.loc[sub.index[0], \"kit name\"] = kit_name\n",
        "            sub.loc[sub.index[1]:, \"kit name\"] = \"\"\n",
        "\n",
        "            # Remove repeated formats within the same kit\n",
        "            last_fmt = None\n",
        "            for i in sub.index:\n",
        "                fmt = sub.at[i, \"format\"]\n",
        "                if fmt == last_fmt:\n",
        "                    sub.at[i, \"format\"] = \"\"\n",
        "                else:\n",
        "                    last_fmt = fmt\n",
        "\n",
        "            pretty_blocks.append(sub[[\"kit name\", \"format\", \"color\", \"quantity\"]])\n",
        "\n",
        "        pretty_summary = pd.concat(pretty_blocks, ignore_index=True)\n",
        "\n",
        "        # Display neatly without index column\n",
        "        display(pretty_summary.style.hide(axis=\"index\"))\n",
        "\n",
        "        # Save full detailed CSV (with all values)\n",
        "        summary.to_csv(\"results/kit_summary.csv\", index=False)\n",
        "        print(\"‚úÖ Summary saved to results/kit_summary.csv\")\n",
        "    else:\n",
        "        print(\"No results to summarize.\")\n",
        "\n",
        "\n",
        "def classify_new_kits(folder=\"./data/Kit\",\n",
        "                      reference_files=None,\n",
        "                      test_files=None):\n",
        "    \"\"\"\n",
        "    Classifies test kits against known reference kits by comparing brick distributions\n",
        "    (size + color quantities only).\n",
        "    \"\"\"\n",
        "\n",
        "    if reference_files is None:\n",
        "        reference_files = [\"kit1.png\", \"kit2.png\", \"kit3.png\"]\n",
        "    if test_files is None:\n",
        "        test_files = [\"ImageA_kit.png\", \"ImageB_kit.png\", \"ImageC_kit.png\"]\n",
        "\n",
        "    print(f\"üîç Running classification in folder: {folder}\")\n",
        "    process_all_kits(folder)\n",
        "\n",
        "    df_all = pd.read_csv(\"results/kit_summary.csv\")\n",
        "\n",
        "    # --- Normalize column names (your table uses Kit, Size, Color, quantity) ---\n",
        "    if \"quantity\" not in df_all.columns:\n",
        "        # fallback capitalization check\n",
        "        for col in df_all.columns:\n",
        "            if col.lower() == \"quantity\":\n",
        "                df_all.rename(columns={col: \"quantity\"}, inplace=True)\n",
        "\n",
        "    df_all.rename(columns={\n",
        "        \"Kit\": \"kit\",\n",
        "        \"Size\": \"size\",\n",
        "        \"Color\": \"color\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # --- Split reference and test kits ---\n",
        "    reference_df = df_all[df_all[\"kit\"].isin(reference_files)]\n",
        "    test_df = df_all[df_all[\"kit\"].isin(test_files)]\n",
        "\n",
        "    print(f\"\\nüì¶ Found {reference_df['kit'].nunique()} reference kits and \"\n",
        "          f\"{test_df['kit'].nunique()} test kits.\\n\")\n",
        "\n",
        "    # --- Build kit compositions ---\n",
        "    def build_comp(df):\n",
        "        out = {}\n",
        "        for kit, sub in df.groupby(\"kit\"):\n",
        "            comp = {f\"{r['size']}_{r['color']}\": int(r['quantity']) for _, r in sub.iterrows()}\n",
        "            out[kit] = comp\n",
        "        return out\n",
        "\n",
        "    reference = build_comp(reference_df)\n",
        "    test_comps = build_comp(test_df)\n",
        "\n",
        "    # --- Compare test kits to references ---\n",
        "    print(\"üß† Comparing test kits to reference kits...\\n\")\n",
        "    results = []\n",
        "    for test_name, test_comp in test_comps.items():\n",
        "        best_match, best_score = None, 0\n",
        "        for ref_name, ref_comp in reference.items():\n",
        "            matches = sum(1 for k, v in test_comp.items() if k in ref_comp and ref_comp[k] == v)\n",
        "            total = max(len(ref_comp), len(test_comp))\n",
        "            score = matches / total if total > 0 else 0\n",
        "            if score > best_score:\n",
        "                best_match, best_score = ref_name, score\n",
        "\n",
        "        status = \"‚úÖ Exact match\" if best_score == 1.0 else (\n",
        "            \"‚ö†Ô∏è Partial match\" if best_score > 0 else \"‚ùå No match\"\n",
        "        )\n",
        "        print(f\"{test_name:<20} ‚Üí {best_match or 'None':<10} ({best_score*100:5.1f}% similarity)  {status}\")\n",
        "        results.append({\n",
        "            \"image\": test_name,\n",
        "            \"match\": best_match or \"None\",\n",
        "            \"similarity\": round(best_score, 3),\n",
        "            \"status\": status\n",
        "        })\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results.to_csv(\"results/kit_comparison.csv\", index=False)\n",
        "    print(\"\\nüìä Classification summary saved ‚Üí results/kit_comparison.csv\")\n",
        "    display(df_results)\n",
        "    return df_results\n",
        "\n",
        "\n",
        "classify_new_kits(\n",
        "    folder=\"./data/Kit\",\n",
        "    reference_files=[\"kit1.png\", \"kit2.png\", \"kit3.png\"],\n",
        "    test_files=[\"ImageA_kit.png\", \"ImageB_kit.png\", \"ImageC_kit.png\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "k4TNB4Ltrrj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 3C)\n",
        "\n",
        "Previous code show kit detection and association between test and reference kits."
      ],
      "metadata": {
        "id": "aAwiXRcy-76j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 3D)\n",
        "\n",
        "For a proper image detection it is very important the calibration process and to ensure the conditions from the calibration process maitained along the time.\n",
        "\n",
        "The image process is very sensitive,  changing of light, distance or angle os view can generate errors in the detection process (because of shadows, glare and other efects).\n",
        "\n",
        "Also the process can take advantage if the position of the pieces is made more regular (for example all pieces in parallel and with a good degree of separation). It would also benefit the process if the background (the surface where the pieces are) is not of the same color of the pieces - e.g. the white pieces were dificult to detect and only with a combination of maks and studs it was possible to do).\n",
        "\n",
        "### EXTRA\n",
        "\n",
        "Use a controlled imaging rig: enclose the belt, add uniform diffuse LED lighting with cross-polarizers, a matte high-contrast background, and global-shutter cameras synced to short strobes to freeze motion and kill glare.\n",
        "Run routine calibration: geometric (checkerboard) and lens distortion, plus color calibration with a reference chart; lock white balance/exposure per line, monitor temperature drift, and re-calibrate on a schedule.\n",
        "Mitigate photometric effects by avoiding shadows and specular highlights, using HDR or exposure bracketing for very shiny/dark pieces, and keeping a linear (gamma-aware) color pipeline so thresholds stay stable.\n",
        "Improve separability before vision: add singulation/spreader rails to reduce overlaps, consider top+side (or 3D) views to see studs and height, and maintain a data-driven re-tuning loop (periodic re-labeling and threshold updates) based on production images.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ffrlruk_s09"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPbzLNME5mf8"
      },
      "source": [
        "## 4Ô∏è‚É£ Faulty Kits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUXILIARY FUNCTION TO INSPECT IMAGE CONDITIONS\n",
        "\n",
        "import cv2, numpy as np, matplotlib.pyplot as plt, seaborn as sns, glob, os\n",
        "\n",
        "def inspect_image_conditions(folder=\"./data/Fault\", n_show=3):\n",
        "    \"\"\"\n",
        "    Inspects basic image statistics (brightness, contrast, color histograms, stud scale hints)\n",
        "    to guide parameter tuning.\n",
        "    \"\"\"\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.png\")))\n",
        "    print(f\"üìÇ Found {len(files)} images in {folder}\\n\")\n",
        "    if not files:\n",
        "        return\n",
        "\n",
        "    stats = []\n",
        "    for path in files:\n",
        "        img = cv2.imread(path)\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        mean_v = hsv[...,2].mean()\n",
        "        mean_s = hsv[...,1].mean()\n",
        "        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "        stats.append({\n",
        "            \"image\": os.path.basename(path),\n",
        "            \"mean_V\": mean_v,\n",
        "            \"mean_S\": mean_s,\n",
        "            \"sharpness\": sharpness,\n",
        "            \"height\": img.shape[0],\n",
        "            \"width\": img.shape[1]\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(stats)\n",
        "    display(df.style.background_gradient(cmap=\"viridis\", subset=[\"mean_V\",\"mean_S\",\"sharpness\"]))\n",
        "\n",
        "    # ---- Brightness & saturation comparison ----\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.barplot(df, x=\"image\", y=\"mean_V\", color=\"gold\")\n",
        "    plt.title(\"Mean Brightness (V channel)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    sns.barplot(df, x=\"image\", y=\"mean_S\", color=\"limegreen\")\n",
        "    plt.title(\"Mean Saturation (S channel)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Example histograms and circle size hint ----\n",
        "    for i, path in enumerate(files[:n_show]):\n",
        "        img = cv2.imread(path)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        plt.figure(figsize=(12,5))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{os.path.basename(path)} ‚Äî Preview\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.hist(gray.ravel(), bins=50, color='gray')\n",
        "        plt.title(\"Grayscale histogram (contrast indicator)\")\n",
        "        plt.xlabel(\"Intensity\"); plt.ylabel(\"Pixels\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\nüí° Interpretation tips:\")\n",
        "    print(\" - Lower mean_V ‚Üí darker images ‚Üí increase exposure/brightness correction or lower Hough param1.\")\n",
        "    print(\" - Lower sharpness ‚Üí blurrier images ‚Üí raise minRadius or preprocess with unsharp mask.\")\n",
        "    print(\" - Very low mean_S ‚Üí faded colors ‚Üí relax HSV saturation thresholds.\")\n",
        "    print(\" - Check grayscale histograms: narrow peaks mean low contrast.\")\n"
      ],
      "metadata": {
        "id": "WXV7njBZcXXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INSPECT IMAGES\n",
        "\n",
        "inspect_image_conditions(\"./data/Fault\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5i__oZNEfut9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üß± LEGO Fault Set ‚Äî per-color brick detection & fault report\n",
        "# ============================================================\n",
        "# Fixes: Tuned white color levels for mask.\n",
        "# Processes ./data/Fault, displays annotated detections,\n",
        "# outputs kit_summary_fault.csv and kit_comparison_fault.csv\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, shutil, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# ======= CONFIG =======\n",
        "PX_PER_MM = 0.330046\n",
        "VALID_STUD_COUNTS = {2: \"2x1\", 4: \"2x2\", 8: \"4x2\", 12: \"6x2\"}\n",
        "STUD_MISS_TOL = 1\n",
        "EPS_MULTIPLIER = 1.23\n",
        "ROI_MARGIN = 10\n",
        "COLORS = [\"red\", \"blue\", \"green\", \"yellow\", \"white\"]\n",
        "\n",
        "# for studs detection\n",
        "PARAM1 = 70   # (was 90)\n",
        "PARAM2 = 18   # (was 20)\n",
        "MINR, MAXR = 6, 18   # (was 5, 16)\n",
        "\n",
        "# for removing close studs\n",
        "MIN_DIST = 35             # Tuned from 30 to 35\n",
        "\n",
        "\n",
        "# ======= UTILS / FUNCTIONS =======\n",
        "def reset_results():\n",
        "    base = \"results\"\n",
        "    if os.path.exists(base):\n",
        "        shutil.rmtree(base)\n",
        "    os.makedirs(\"results/annotated\", exist_ok=True)\n",
        "    os.makedirs(\"results/debug\", exist_ok=True)\n",
        "\n",
        "def mm2_from_px_area(px_area):\n",
        "    return float(px_area) * (PX_PER_MM ** 2)\n",
        "\n",
        "\"\"\"\n",
        "===============================================================================\n",
        "üîç STUD DETECTION CONFIGURATION ‚Äî FINAL TUNED PARAMETERS\n",
        "===============================================================================\n",
        "\n",
        "Function: detect_all_studs(img_bgr, color_hint=None)\n",
        "\n",
        "Detection method:\n",
        "- Converts to grayscale ‚Üí equalizes histogram ‚Üí median blur\n",
        "- Applies color-specific Hough Circle parameters\n",
        "- For white, applies a sharpening filter before Hough (boost edges)\n",
        "\n",
        "Color | Hough Parameters | Notes\n",
        "------|------------------|------\n",
        "üî¥ red     | param1=55, param2=12, minR=5,  maxR=18 | Low thresholds to catch weak red edges.\n",
        "üü° yellow  | param1=65, param2=17, minR=5,  maxR=16 | Balanced; combined with eps*1.10 in DBSCAN.\n",
        "üü¢ green   | param1=90, param2=18, minR=5,  maxR=16 | Moderate sensitivity.\n",
        "üîµ blue    | param1=90, param2=18, minR=5,  maxR=16 | Stable; limited noise.\n",
        "‚ö™ white   | param1=75, param2=17, minR=5,  maxR=16 | Edge-sharpened preprocessing.\n",
        "\n",
        "Additional global parameters:\n",
        "--------------------------------\n",
        "PX_PER_MM         = 0.330046      # pixel‚Äìto‚Äìmm conversion factor\n",
        "VALID_STUD_COUNTS = {2:'2x1', 4:'2x2', 8:'4x2', 12:'6x2'}\n",
        "STUD_MISS_TOL     = 1             # Snap tolerance (¬±1 stud)\n",
        "EPS_MULTIPLIER    = 1.10 (yellow) # Slightly larger DBSCAN eps for yellow\n",
        "MIN_DIST          = 30            # Minimum inter-stud distance\n",
        "ROI_MARGIN        = 10            # Padding for bounding boxes\n",
        "\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "# function to detect all studs in image with color hint\n",
        "def detect_all_studs(img_bgr, color_hint=None):\n",
        "    \"\"\"\n",
        "    Detect LEGO studs using tuned HoughCircles, adaptive per color_hint.\n",
        "    color_hint can be one of: 'red', 'yellow', 'green', 'blue', 'white', or None.\n",
        "    \"\"\"\n",
        "\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "    gray = cv2.medianBlur(gray, 3)\n",
        "\n",
        "    # --- Default parameters ---\n",
        "    param1 = PARAM1   # upper threshold for edge detection\n",
        "    param2 = PARAM2   # accumulator threshold (lower ‚Üí more circles)\n",
        "    minR, maxR = MINR, MAXR\n",
        "\n",
        "    # --- Adjust based on color ---\n",
        "    if color_hint == 'red':\n",
        "        param1 = 55   # lower edge threshold ‚Üí catches weak edges\n",
        "        param2 = 12   # even more sensitive accumulator\n",
        "        minR, maxR = 5, 18\n",
        "    elif color_hint == 'yellow':\n",
        "        param2 = 17   # stricter (avoid false positives) 23 was 18\n",
        "        param1 = 65   # was 100 com 80 melhorou was 80\n",
        "    elif color_hint == 'green':\n",
        "        param2 = 18   # was 20\n",
        "    elif color_hint == 'blue':\n",
        "        param2 = 18   # was 20\n",
        "    elif color_hint == 'white':\n",
        "        param2 = 20   # was 22\n",
        "\n",
        "    circles = cv2.HoughCircles(\n",
        "        gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=18,\n",
        "        param1=param1, param2=param2,\n",
        "        minRadius=minR, maxRadius=maxR\n",
        "    )\n",
        "\n",
        "    if circles is None:\n",
        "        return np.empty((0, 2), dtype=np.float32)\n",
        "\n",
        "    C = np.uint16(np.around(circles[0]))\n",
        "    return C[:, :2].astype(np.float32)\n",
        "\n",
        "# function to remove stud that is too close to other\n",
        "def remove_too_close_studs(studs, min_dist=8):\n",
        "    if len(studs) < 3: return studs\n",
        "    keep = []\n",
        "    used = np.zeros(len(studs), dtype=bool)\n",
        "    for i in range(len(studs)):\n",
        "        if used[i]: continue\n",
        "        keep.append(studs[i])\n",
        "        for j in range(i+1, len(studs)):\n",
        "            if np.linalg.norm(studs[i]-studs[j]) < min_dist:\n",
        "                used[j] = True\n",
        "    return np.array(keep, dtype=np.float32)\n",
        "\n",
        "# function to estimate eps from all points\n",
        "def estimate_eps_from_spacing(points):\n",
        "    if len(points) < 2: return 40.0\n",
        "    tree = cKDTree(points)\n",
        "    dists, _ = tree.query(points, k=2)\n",
        "    nn = np.median(dists[:, 1])\n",
        "    return float(max(EPS_MULTIPLIER * nn, 25.0))\n",
        "\n",
        "# function to create ROI boxes from clusters\n",
        "def boxes_from_stud_clusters(points, labels, margin=ROI_MARGIN):\n",
        "    rois = []\n",
        "    for lab in sorted(set(labels)):\n",
        "        if lab == -1: continue\n",
        "        P = points[labels == lab]\n",
        "        x1, y1 = np.min(P, axis=0)\n",
        "        x2, y2 = np.max(P, axis=0)\n",
        "        x1, y1 = int(x1 - margin), int(y1 - margin)\n",
        "        x2, y2 = int(x2 + margin), int(y2 + margin)\n",
        "        rois.append((x1, y1, max(1,x2-x1), max(1,y2-y1), lab))\n",
        "    return rois\n",
        "\n",
        "# function to remove overlap ROI\n",
        "def remove_overlaps_keep_largest(rois, iou_thresh=0.4, dist_ratio=0.6):\n",
        "    \"\"\"Gentle overlap filtering to preserve small bricks.\"\"\"\n",
        "    def inter_over_min(a, b):\n",
        "        ax1, ay1, aw, ah = a[:4]\n",
        "        bx1, by1, bw, bh = b[:4]\n",
        "        ax2, ay2 = ax1 + aw, ay1 + ah\n",
        "        bx2, by2 = bx1 + bw, by1 + bh\n",
        "        xA, yA = max(ax1, bx1), max(ay1, by1)\n",
        "        xB, yB = min(ax2, bx2), min(ay2, by2)\n",
        "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
        "        areaA, areaB = aw * ah, bw * bh\n",
        "        return inter / max(1, min(areaA, areaB))\n",
        "\n",
        "    keep = []\n",
        "    # Sort by area descending ‚Äî keep bigger first\n",
        "    for r in sorted(rois, key=lambda x: x[2] * x[3], reverse=True):\n",
        "        if all(inter_over_min(r, k) < iou_thresh for k in keep):\n",
        "            keep.append(r)\n",
        "    return keep\n",
        "\n",
        "# function to adjust stud count (it helps in case of missing stud detection)\n",
        "def snap_stud_count(n):\n",
        "    \"\"\"\n",
        "    Snap stud count to nearest valid size (2, 4, 8, 12)\n",
        "    with ¬±STUD_MISS_TOL tolerance, preferring upward snaps on ties.\n",
        "    \"\"\"\n",
        "\n",
        "    n = int(n)\n",
        "\n",
        "    if n == 6:\n",
        "      return 4   # treat 6 as an overcounted 2√ó2 brick\n",
        "\n",
        "    candidates = np.array(sorted(VALID_STUD_COUNTS.keys()))  # [2, 4, 8, 12]\n",
        "    diffs = np.abs(candidates - n)\n",
        "    min_diff = diffs.min()\n",
        "\n",
        "    # candidates with same min difference\n",
        "    nearest_candidates = candidates[diffs == min_diff]\n",
        "    # prefer larger when tied\n",
        "    nearest = int(nearest_candidates.max())\n",
        "\n",
        "    if abs(nearest - n) <= STUD_MISS_TOL:\n",
        "        return nearest\n",
        "    return None\n",
        "\n",
        "\"\"\"\n",
        "===============================================================================\n",
        "üé® COLOR MASK CONFIGURATION ‚Äî FINAL TUNED PARAMETERS\n",
        "===============================================================================\n",
        "\n",
        "Each color is extracted in HSV space with specific thresholds and morphology.\n",
        "These values were tuned empirically for the current dataset of LEGO kit images.\n",
        "\n",
        "Color | HSV Lower (H,S,V) | HSV Upper (H,S,V) | Morphology | Notes\n",
        "------|-------------------|-------------------|-------------|------\n",
        "üî¥ red     | (0,100,60) & (170,100,60) | (10,255,255) & (180,255,255) | ‚Äî | Two ranges handle hue wraparound. Very sensitive (weak edges).\n",
        "üü° yellow  | (10,90,90) | (34,255,255) | close(7√ó7) ‚Üí dilate(7√ó7) | Avoids overlap with green. Dilation keeps edge studs visible.\n",
        "üü¢ green   | (40,60,50) | (85,255,255) | close(7√ó7) | Balanced ‚Äî minimal false positives.\n",
        "üîµ blue    | (90,60,40) | (130,255,255) | close(7√ó7) | Stable under mild shadows.\n",
        "‚ö™ white   | (0,0,200) | (180,60,255) | close(5√ó5) ‚Üí open(5√ó5) ‚Üí erode(3√ó3) | Tight V/S limits remove reflections & background glare.\n",
        "\n",
        "Morphology legend:\n",
        "- close(): fills small holes inside the mask (connects studs)\n",
        "- open(): removes isolated bright noise pixels\n",
        "- erode(): shrinks glare halos and prevents brick merging\n",
        "\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "# function to apply color mask\n",
        "def make_color_mask(img_bgr, color):\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "    if color == \"yellow\":\n",
        "        lower, upper = (10, 80, 80), (35, 255, 255)       #(10, 100, 100), (35, 255, 255)\n",
        "\n",
        "    elif color == \"red\":\n",
        "        lower1, upper1 = (0, 100, 60), (10, 255, 255)     #(0, 120, 70), (10, 255, 255)\n",
        "        lower2, upper2 = (170, 100, 60), (180, 255, 255)  #(170, 120, 70), (180, 255, 255)\n",
        "        return (cv2.inRange(hsv, np.array(lower1), np.array(upper1)) |\n",
        "                cv2.inRange(hsv, np.array(lower2), np.array(upper2)))\n",
        "    elif color == \"blue\":\n",
        "        lower, upper = (90, 60, 40), (130, 255, 255)      #(90, 80, 50), (130, 255, 255)\n",
        "    elif color == \"green\":\n",
        "        lower, upper = (35, 50, 40), (85, 255, 255)       #(40, 60, 50), (85, 255, 255)\n",
        "    elif color == 'white':\n",
        "\n",
        "        # White has very low saturation and high brightness\n",
        "        lower = (0,0,200)       # This is what works better for this case - before was (0, 0, 180)\n",
        "        upper = (180, 60, 255)  # This is what works better for this case - before was (180, 40, 255)\n",
        "        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "\n",
        "        # Morphological cleaning to remove noise and fill holes\n",
        "        kernel = np.ones((5,5), np.uint8)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Extra step: erode slightly to avoid merging with bright reflections\n",
        "        mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=1)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown color: {color}\")\n",
        "    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((7,7), np.uint8))    # was 9,9\n",
        "    return mask\n",
        "\n",
        "# function to keep only studs that are inside color mask\n",
        "def keep_studs_inside_mask(studs, mask):\n",
        "    h, w = mask.shape\n",
        "    kept = []\n",
        "    for (x, y) in studs:\n",
        "        xi, yi = int(round(x)), int(round(y))\n",
        "        if 0 <= xi < w and 0 <= yi < h and mask[yi, xi] > 0:\n",
        "            kept.append([x, y])\n",
        "    return np.array(kept, dtype=np.float32)\n",
        "\n",
        "# === Helper: clean results folders ===\n",
        "def reset_results(base_results):\n",
        "    import shutil\n",
        "    for sub in [\"debug\", \"annotated\"]:\n",
        "        path = os.path.join(base_results, sub)\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        for f in os.listdir(path):\n",
        "            os.remove(os.path.join(path, f))\n",
        "\n",
        "# === Main processing function ===\n",
        "def process_all_kits(folder=\"./data/Kit\", results_name=\"kit\"):\n",
        "\n",
        "    base_results = f\"results_{results_name}\"\n",
        "    os.makedirs(base_results, exist_ok=True)\n",
        "    reset_results(base_results)\n",
        "\n",
        "    all_rows = []\n",
        "    for kit_path in sorted(glob.glob(os.path.join(folder, \"*.png\"))):\n",
        "\n",
        "        name = os.path.basename(kit_path)\n",
        "        print(f\"\\nüîπ Processing {name}\")\n",
        "        img = cv2.imread(kit_path)\n",
        "\n",
        "        dbg, vis = img.copy(), img.copy()\n",
        "        roi_id = 1\n",
        "\n",
        "        for color in COLORS:\n",
        "            mask = make_color_mask(img, color)\n",
        "\n",
        "            studs_raw = detect_all_studs(img, color_hint=color)\n",
        "            # ADD PRINT - debug\n",
        "            print(f\"[{color}] raw studs={len(studs_raw)}\")\n",
        "\n",
        "            studs = keep_studs_inside_mask(studs_raw, mask)\n",
        "            # ADD PRINT - debug\n",
        "            print(f\"   after mask filter: {len(studs)}\")\n",
        "\n",
        "            studs = remove_too_close_studs(studs, min_dist=MIN_DIST)\n",
        "            # ADD PRINT - debug\n",
        "            print(f\"   after too-close filter: {len(studs)}\")\n",
        "\n",
        "            if len(studs)==0:\n",
        "                continue\n",
        "\n",
        "            # CLUSTER PROCESS\n",
        "\n",
        "            eps = estimate_eps_from_spacing(studs)\n",
        "\n",
        "            #FIX FOR YELLOW (tunning)\n",
        "            if color == \"yellow\":\n",
        "              eps *= 1.10  # increase by 25% only for yellow\n",
        "\n",
        "            labels = DBSCAN(eps=eps, min_samples=2).fit_predict(studs)\n",
        "\n",
        "            # ADD PRINT - debug\n",
        "            print(f\"[{color}] studs={len(studs)}, unique DBSCAN labels={set(labels)} (eps={eps:.1f})\")\n",
        "\n",
        "            rois = boxes_from_stud_clusters(studs, labels)\n",
        "            rois = remove_overlaps_keep_largest(rois)\n",
        "\n",
        "            for (x,y,w,h,lab) in rois:\n",
        "                studs_in = studs[labels==lab]\n",
        "                n_studs = len(studs_in)\n",
        "                snapped = snap_stud_count(n_studs)\n",
        "                label = VALID_STUD_COUNTS.get(snapped, \"unknown\")\n",
        "\n",
        "                # ADD PRINT - debug\n",
        "                print(f\"   cluster {lab}: {n_studs} studs ‚Üí snapped={snapped}, label={label}\")\n",
        "\n",
        "                cv2.rectangle(dbg,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "                cv2.putText(dbg,f\"ROI {roi_id}\",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
        "                for (sx,sy) in studs_in:\n",
        "                    cv2.circle(dbg,(int(sx),int(sy)),3,(255,0,0),-1)\n",
        "                roi_id+=1\n",
        "\n",
        "                cv2.rectangle(vis,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "                cv2.putText(vis,f\"{color} {label}\",(x,y-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
        "\n",
        "                cx, cy = int(x + w / 2), int(y + h / 2)\n",
        "                cv2.circle(dbg, (cx, cy), 4, (0, 0, 0), -1)\n",
        "                cv2.circle(vis, (cx, cy), 4, (0, 0, 0), -1)\n",
        "\n",
        "                all_rows.append({\"Kit\":name,\"Color\":color,\"Size\":label,\"Studs\":n_studs})\n",
        "\n",
        "        # Save images\n",
        "        cv2.imwrite(f\"{base_results}/debug/{name}_rois.png\", dbg)\n",
        "        cv2.imwrite(f\"{base_results}/annotated/{name}_bricks.png\", vis)\n",
        "\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî ROI Debug (red boxes = clusters, blue dots = studs)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"{name} ‚Äî Bricks Labeled (yellow boxes)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        summary = (\n",
        "            df.groupby([\"Kit\", \"Size\", \"Color\"])\n",
        "              .size()\n",
        "              .reset_index(name=\"quantity\")\n",
        "              .sort_values([\"Kit\", \"Size\", \"Color\"])\n",
        "        )\n",
        "\n",
        "        print(\"\\nüìä Final Results ‚Äî Bricks per Kit\\n\")\n",
        "\n",
        "        pretty_blocks = []\n",
        "        for kit_name, sub in summary.groupby(\"Kit\", sort=False):\n",
        "            sub = sub.copy()\n",
        "            sub = sub.rename(columns={\"Kit\": \"kit name\", \"Size\": \"format\", \"Color\": \"color\"})\n",
        "            sub.loc[sub.index[0], \"kit name\"] = kit_name\n",
        "            sub.loc[sub.index[1]:, \"kit name\"] = \"\"\n",
        "            last_fmt = None\n",
        "            for i in sub.index:\n",
        "                fmt = sub.at[i, \"format\"]\n",
        "                if fmt == last_fmt:\n",
        "                    sub.at[i, \"format\"] = \"\"\n",
        "                else:\n",
        "                    last_fmt = fmt\n",
        "            pretty_blocks.append(sub[[\"kit name\", \"format\", \"color\", \"quantity\"]])\n",
        "\n",
        "        pretty_summary = pd.concat(pretty_blocks, ignore_index=True)\n",
        "        display(pretty_summary.style.hide(axis=\"index\"))\n",
        "\n",
        "        csv_path = f\"{base_results}/kit_summary_{results_name}.csv\"\n",
        "        summary.to_csv(csv_path, index=False)\n",
        "        print(f\"‚úÖ Summary saved to {csv_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No results to summarize.\")\n",
        "\n",
        "\n",
        "def classify_new_kits(folder=\"./data/Fault\",\n",
        "                      results_name=\"fault\",\n",
        "                      reference_files=None,\n",
        "                      test_files=None):\n",
        "\n",
        "    base_results = f\"results_{results_name}\"\n",
        "    os.makedirs(base_results, exist_ok=True)\n",
        "\n",
        "    print(f\"üîç Running classification in folder: {folder}\")\n",
        "    process_all_kits(folder, results_name=results_name)\n",
        "\n",
        "    df_all = pd.read_csv(f\"{base_results}/kit_summary_{results_name}.csv\")\n",
        "\n",
        "    df_all.rename(columns={\"Kit\": \"kit\", \"Size\": \"size\", \"Color\": \"color\"}, inplace=True)\n",
        "\n",
        "    reference_df = df_all[df_all[\"kit\"].isin(reference_files)]\n",
        "    test_df = df_all[df_all[\"kit\"].isin(test_files)]\n",
        "\n",
        "    print(f\"\\nüì¶ Found {reference_df['kit'].nunique()} reference kits and \"\n",
        "          f\"{test_df['kit'].nunique()} test kits.\\n\")\n",
        "\n",
        "    def build_comp(df):\n",
        "        out = {}\n",
        "        for kit, sub in df.groupby(\"kit\"):\n",
        "            comp = (\n",
        "                sub.groupby([\"size\", \"color\"])[\"quantity\"]\n",
        "                  .sum()\n",
        "                  .apply(int)\n",
        "                  .to_dict()\n",
        "            )\n",
        "            # Flatten to \"size_color\" keys\n",
        "            comp = {f\"{size}_{color}\": qty for (size, color), qty in comp.items()}\n",
        "            out[kit] = comp\n",
        "        return out\n",
        "\n",
        "    reference = build_comp(reference_df)\n",
        "    test_comps = build_comp(test_df)\n",
        "\n",
        "\n",
        "    print(\"üß† Comparing test kits to reference kits...\\n\")\n",
        "    results = []\n",
        "\n",
        "    for test_name, test_comp in test_comps.items():\n",
        "        best_match, best_score, best_diff_comment = None, 0, \"\"\n",
        "\n",
        "        for ref_name, ref_comp in reference.items():\n",
        "            # --- Compare test vs reference ---\n",
        "            matches = sum(1 for k, v in test_comp.items() if k in ref_comp and ref_comp[k] == v)\n",
        "            total = max(len(ref_comp), len(test_comp))\n",
        "            score = matches / total if total > 0 else 0\n",
        "\n",
        "            # --- Keep best match ---\n",
        "            if score > best_score:\n",
        "                best_match, best_score = ref_name, score\n",
        "\n",
        "                # --- Compute differences ---\n",
        "                missing, exceeding = [], []\n",
        "\n",
        "                # Bricks missing or lower count than reference\n",
        "                for k, v in ref_comp.items():\n",
        "                    if k not in test_comp:\n",
        "                        missing.append(f\"{k} (x{v} missing)\")\n",
        "                    elif test_comp[k] < v:\n",
        "                        diff = v - test_comp[k]\n",
        "                        missing.append(f\"{k} (x{diff} missing)\")\n",
        "\n",
        "                # Bricks exceeding or absent in reference\n",
        "                for k, v in test_comp.items():\n",
        "                    if k not in ref_comp:\n",
        "                        exceeding.append(f\"{k} (x{v} extra)\")\n",
        "                    elif test_comp[k] > ref_comp[k]:\n",
        "                        diff = test_comp[k] - ref_comp[k]\n",
        "                        exceeding.append(f\"{k} (x{diff} extra)\")\n",
        "\n",
        "                # Build human-readable comment\n",
        "                comments = []\n",
        "                if missing:\n",
        "                    comments.append(\"Missing: \" + \", \".join(missing))\n",
        "                if exceeding:\n",
        "                    comments.append(\"Extra: \" + \", \".join(exceeding))\n",
        "                best_diff_comment = \" | \".join(comments) if comments else \"All bricks match.\"\n",
        "\n",
        "        # --- Assign status and print summary ---\n",
        "        if best_score == 1.0:\n",
        "            status = \"‚úÖ Exact Match\"\n",
        "        elif best_score > 0:\n",
        "            status = \"‚ùå Faulty Kit\"   # renamed from Partial Match\n",
        "        else:\n",
        "            status = \"‚ùå No Match\"\n",
        "\n",
        "        print(f\"{test_name:<20} ‚Üí {best_match or 'None':<10} ({best_score*100:5.1f}% similarity)  {status}\")\n",
        "        print(f\"   ‚Ü™ {best_diff_comment}\")\n",
        "\n",
        "        results.append({\n",
        "            \"image\": test_name,\n",
        "            \"match\": best_match or \"None\",\n",
        "            \"similarity\": round(best_score, 3),\n",
        "            \"status\": status,\n",
        "            \"comment\": best_diff_comment\n",
        "        })\n",
        "\n",
        "    # --- Save final DataFrame ---\n",
        "    df_results = pd.DataFrame(results)\n",
        "    out_csv = f\"{base_results}/kit_comparison_{results_name}.csv\"\n",
        "    df_results.to_csv(out_csv, index=False)\n",
        "\n",
        "    print(f\"\\nüìä Classification summary saved ‚Üí {out_csv}\")\n",
        "    display(df_results)\n",
        "    return df_results\n",
        "\n",
        "\n",
        "#RUN PROCESS\n",
        "\n",
        "final_result = classify_new_kits(\n",
        "                  folder=\"./data/Fault\",\n",
        "                  results_name=\"fault\",\n",
        "                  reference_files=[\"kitA.png\", \"kitB.png\", \"kitC.png\"],\n",
        "                  test_files=[\"ImageA_fault.png\", \"ImageB_fault.png\", \"ImageC_fault.png\",\n",
        "                              \"imageD_fault.png\", \"ImageE_fault.png\", \"ImageF_fault.png\"]\n",
        "                  )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "REnlo0M8BqWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results - Answer to Question 4)\n",
        "\n",
        "Previous code show kit detection and association between test and reference kits (for FAULT images folder)."
      ],
      "metadata": {
        "id": "ku9AUylZLvca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUXILIARY FUNCTION TO OBSERVE WHAT IS BEING DONE BY MASK AND STUD DETECTION\n",
        "\n",
        "def inspect_detection_steps(img_path, color=\"yellow\"):\n",
        "    \"\"\"\n",
        "    Visualize mask quality and stud detection overlay for a single color.\n",
        "    Helps decide if issues come from HSV mask or Hough parameters.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    #hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    mask = make_color_mask(img, color)\n",
        "    studs = detect_all_studs(img, color_hint=color)\n",
        "    studs = keep_studs_inside_mask(studs, mask)\n",
        "    studs = remove_too_close_studs(studs, min_dist=MIN_DIST)\n",
        "\n",
        "    # Prepare overlay visualization\n",
        "    overlay = img.copy()\n",
        "    overlay[mask > 0] = (0.3 * overlay[mask > 0] + 0.7 * np.array([0,255,255])).astype(np.uint8)\n",
        "    for (x, y) in studs:\n",
        "        cv2.circle(overlay, (int(x), int(y)), 5, (255, 0, 0), -1)\n",
        "\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Image\"); plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(mask, cmap=\"gray\")\n",
        "    plt.title(f\"Mask for {color}\"); plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Detected studs on {color} mask overlay\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"üîπ Studs detected: {len(studs)}\")"
      ],
      "metadata": {
        "id": "wcmDJFcBlryk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INSPECTION TO DETECT EDGE CASES\n",
        "\n",
        "inspect_detection_steps(\"./data/Fault/ImageA_fault.png\", color=\"white\")\n",
        "\n",
        "inspect_detection_steps(\"./data/Fault/ImageA_fault.png\", color=\"yellow\")\n",
        "\n",
        "inspect_detection_steps(\"./data/Fault/ImageA_fault.png\", color=\"red\")\n",
        "\n",
        "inspect_detection_steps(\"./data/Fault/ImageE_fault.png\", color=\"yellow\")\n",
        "\n",
        "inspect_detection_steps(\"./data/Fault/ImageB_fault.png\", color=\"yellow\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FFKXfmn_lvRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}